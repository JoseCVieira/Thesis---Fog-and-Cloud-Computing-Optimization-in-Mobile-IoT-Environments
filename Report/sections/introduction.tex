%!TEX encoding = UTF-8 Unicode
\section{Introduction}\label{sec:Introduction}
%Context - IoT
\noindent
World is growing at a fast pace and so is data. Agility and flexibility of big data applications are gradually taking the form of the Internet of Things (IoT) and there’s no doubt that it is a great resource. It comprises \textit{things} that have unique identities and are connected to the Internet (e.g., vehicles, home appliances, wearable devices). The number of mobile devices are predicted to reach 11.6 billion by 2021, exceeding the world’s projected population at that time (7.8 billion), where the subset of IoT ones are expected to be 929 million \cite{CiscoVis16:online}. \\
%Ubiquitous deployment of smart, interconnected devices1 is estimated to reach 50 billion units by 20202. This exponential increase is fueled by the proliferation of mobile devices (e.g. mobile phones and tablets), smart sensors serving different vertical markets (e.g. smart power grids, autonomous transportation, industrial controls, smart cities3, wearables, etc), wireless sensors and actuators networks.
\noindent\tab Managing the data generated by IoT sensors and actuators is one of the biggest challenges faced when deploying an IoT system. Although this kind of devices has evolved radically in the last years, battery life, computation and storage capacity remain limited. This means that they are not suitable for running heavy applications, being necessary, in this case, to resort to third parties.\\
%Context - CLOUD COMPUTING
\noindent\tab Cloud computing (CC) is a resource-rich environment that has been imperative in expanding the reach and capabilities of IoT devices. It enables that clients outsource the allocation and management of resources (hardware or software) that they rely upon to the cloud. In addition, to avoid over- or under-provisioning, cloud service providers (CSPs) also afford dynamic resources for a scalable workload, applying a pay-as-you-go cost model. So, cloud computing is the on-demand delivery of compute power, database storage, applications, and other IT resources through a cloud services platform via the internet with pay-as-you-go pricing. %[https://aws.amazon.com/what-is-cloud-computing/].
This way, besides overcoming the aforementioned limitations, it also brings other advantages such as availability, flexibility, scalability, reliability, to mention a few.\\
\noindent\tab Despite the benefits of using cloud computing, two main problems, linked to IoT applications, remain unresolved and they can not be underestimated. The first, and the most obvious, is the fact that cloud servers reside in remote data centers and, consequently, the end-to-end communication have long delays (characteristic of multi-hops transmissions over the Internet). Some applications, with ultra-low latency requirements, can't support such delays. Augmented reality applications that use head-tracked systems, for example, require end-to-end latencies to be less than 16 ms \cite{ellis2004generalizeability}. Cloud-based virtual desktop applications require end-to-end latency below 60 ms if they are to match QoS of local execution \cite{taylor2015virtual}. Remotely rendered video conference, on the other hand, demand end-to-end latency below 150 ms \cite{szigeti2005end}. On the other hand, the constantly growing number of IoT devices raises the other problem. The basic premise is that as the number of connected devices increases, the bandwidth required to support them becomes too large for centralized processing (i.e. CC). As a fallout of this sense-process-actuate model, where the processing is done in the cloud, there are two immediately apparent options: (1) increase the number of centralized cloud data centers, what will be too costly, and (2) get more efficient with the data sent to the cloud.\\
\noindent\tab To overcome this limitations, the solution that has already been proposed is to bring the cloud closer to the end devices, where entities such as base-stations would host smaller sized clouds. This idea has brought the emergence of several computing paradigms such as cloudlets \cite{satyanarayanan2013cloudlets}, fog computing \cite{bonomi2012fog}, edge computing \cite{davy2014challenges}, and follow me cloud \cite{taleb2013follow}, to name a few. These are different solutions, that are often confused in the literature, that provide faster approaches that gain better situational awareness in a far more timely manner. However, they all share the same goal, achieve the option number (2), doing more processing in the things-to-cloud continuum instead of in the cloud.\\
%Context - FOG COMPUTING
\noindent\tab As it will be discussed later, fog computing, also known as fog networking or fogging, is the most comprehensive and natural paradigm to get more efficient with the data sent to the cloud. A simple definition of fog is ``cloud closer to the ground'', which gives an idea of its functioning. It is a decentralized computing infrastructure that aims to enable computing, storage, networking, and data management not only in the cloud, but also along the cloud-to-thing path as data traverses to the cloud. Essentially it extends cloud computing and services along the network itself, bringing them closer to where data is created and acted upon. Fog brought this services closer to the end devices due to its low hardware footprint and consequently low power consumption. This way, both problems raised by the use of cloud computing, are solved. First, the path traveled by the data in the architecture sense-process-actuate is much smaller (ideally, just one hop to send data and another to receive the results), allowing latency to be much smaller, compared to the traditional cloud computing. Second, through geographical distribution, there is a significant amount of data that is no longer traveling to the cloud. Fog computing, prefers to process data, as much as possible, in the nodes closer to the edge and, in a simplistic way, it only considers to transfer the data further if there is not enough computational power to meet the demands.\\
\noindent\tab Nevertheless, cloud is still more suitable than fog for massive data processing, when the latency constraints are not so tight. Therefore, even though fog computing has been proposed to grant support for IoT applications, it does not replace the needs of cloud-based services. In fact, fog and cloud complement each other, and one cannot replace the need of the other. Together, they offer services even further optimized to IoT applications. Moreover, Internet connectivity is not essential for the fog-based services to work, what means that services can work independently and send necessary updates to the cloud whenever the connection is available \cite{yousefpour2018all}.\\
\noindent\tab Nonetheless, it is worth mentioning that similarly to cloud computing, fog can use the concept of virtualization to grant heterogeneity. IoT applications may span many different operating systems and application environments (e.g., Android, iOS, Linux, Windows), as well as diverse approaches to partitioning and offloading computation. There is churn in this space from new OS versions, patches to existing OS versions, new libraries, new language runtime systems, and so on. In order to fog support all these variants, it can be introduced a level of abstraction that cleanly encapsulate this messy complexity in a virtual machine (VM). Also, it enables VMs to coexist in a physical server (host) to share resources. Meanwhile, in fog computing, the use of VMs is also crucial to provide mobility. As the end devices become more distant from their current connected fog server, their application needs to be migrated to a more favorable one towards meeting its quality of service (QoS) requirements (e.g., latency) and improve their quality of experience (QoE). This transference can be achieved through migration capabilities of VMs, which can be used to move applications and data through fog nodes according to device mobility (i.e. location). Summing up, in this context, virtualization is a vital technology at different levels namely: (1) isolation between untrusted user-level computations, (2) mechanisms for authentication, access control, and metering, (3) dynamic resource allocation for user-level computations, (4) the ability to support a very wide range of user-level computations, with minimal restrictions on their process structure, programming languages or operating systems \cite{Cloudlet83:online}, (5) mobility, migration and tasks offloading mechanisms, (6) power efficiency, (7) fault tolerance.\\
\subsection{Motivation}\label{subsec:Motivation}
%The problem / Motivation
\noindent\tab Despite the benefits that fog promises to offer such as low latency, heterogeneity, scalability and mobility, the current model suffer from some limitations that still require efforts to overcome them.\\
%The problem / Motivation - MOBILE FOG COMPUTING
\noindent\tab There is lack of support for mobile fog computing. Most of the existing literature assumes that the fog nodes are fixed, or only considers the mobility of IoT devices \cite{yousefpour2018all}. Less attention has been paid to mobile fog computing and how it can improve the QoS, cost, and energy consumption. For instance, a bus could have computational power; as a fog node, it cloud provide offloading support to both end devices (inside and outside it) and other fog servers. The same could be applied to cars that are nowadays getting increasingly better in terms of computational power. Both would be extremely useful to enhance the resources and capabilities of fog computing in environments such as large urban areas, where traffic congestion is frequent or when they are parked (e.g., while an electric vehicle is charging). On top of that, it would reduce the implementation costs since it would no longer require such computational power in the fixed fog nodes. Finally, would reduce the costs to the client both in terms of latency and energy consumption since the fog nodes where they are connected may be even closer.\\
%The problem / Motivation - MULTI-OBJECTIVE FOG SYSTEM DESIGN
\noindent\tab Another limitation of fog computing is to take into account few parameters in the decision making of migration. Most of the existing schemes that are proposed for fog systems, such as offloading, load balancing, or service provisioning, only consider few objectives (e.g., QoS, cost) and assume other objectives do not affect the problem \cite{yousefpour2018all}. Fog servers are less powerful than clouds due to the high deployment cost. If many requests are made to the same fog node at the same time, it will not have enough computational and storage power to give a prompt response. So it raises the question: \textit{should a service currently running in one fog node be migrated to another one, and if yes, where?} While conceptually simple, it is challenging to make these decisions in an optimal manner. Offloading tasks to the next server (i.e. upstream server) seems to be the solution, however, migrate the VM that was initially one-hop away from the IoT device to a multi-hop away server, will increase the network distance. Consequently, raises the end-to-end latency and the bandwidth usage by the intermediate links. Besides, this decision still has to take into account the cost for both the client (e.g., migration time, computational delay) and the provider (e.g., computing and migration energy). Ignoring some of these parameters can lead to wrong decisions, that will both violate latency constraints of user's application and damage or defeat the credibility of fog computing.
%Alternatives ?? \\
%Our approach ?? \\
%Contributions ?? \\
\subsection{Objectives}\label{subsec:Objectives}
\noindent\tab Summing up, this work intend to tackle two of the current limitations that are little or no treated in the literature. One is to provide mobility support in fog computing environments, not exclusively to the end devices but also to the fog nodes and the other is to achieve multi-objective fog system design. These objectives shall be implemented in a toolkit allowing the simulation of resource management techniques in IoT and mobile fog computing environments. In order to achieve the aforementioned goals, this work involves studying the current mobility approaches publicly available with respect to IoT or fog nodes, analyze several optimization algorithms adopted in the field of data placement, propose our own architecture and target the toolkit in which we want to implement it.

%\begin{itemize}
%	\item Propose mobile fog computing, where fog nodes can move, provisioning a method to keep the service always-available for IoT nodes;
%	\item Design of mobility-aware task offloading when fog nodes are mobile,
%	taking into account the related costs to the client (i.e. migration, communication and processing delay) and discovery;
%	\item Propose a variation to achieve multi-objective (i.e. QoS, QoE, cost,
%	handover, load balancing, energy, bandwidth and VMs or virtual objects	migration);
%	\item Study the current open source simulators for fog computing environments;
%\item Implement the proposed algorithms in the simulator and compare them.
%\end{itemize}

%Road map
\noindent\tab The remainder of the document is structured as follows. Section
\ref{sec:RelatedWork} xxx. Section \ref{sec:Architecture} describes xxxx.
Section \ref{sec:Evaluation} defines the xxx. Finally, Section
\ref{sec:Schedule} presents xxxx and Section \ref{sec:Conclusion} xxxx.