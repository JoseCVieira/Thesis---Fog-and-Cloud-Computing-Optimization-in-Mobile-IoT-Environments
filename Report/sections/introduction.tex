%!TEX encoding = UTF-8 Unicode
\section{Introduction}\label{sec:Introduction}
%Context - CLOUD COMPUTING
\noindent
Cloud computing is a computing technology that became popular at the beginning of the twenty-first century, which provide users online accesses to services, employing large groups of computers, servers, disks, and routers interlinked together in a distributed and complex manner. Cloud computing has been imperative in expanding the reach and capabilities of computing, storage, data management, and networking infrastructure to the applications. The key idea in this model is that clients outsource the allocation and management of resources (hardware or software) that they rely upon to the cloud. Clouds can provide different service models according to the end user applications needs, like infrastructure as a service (IaaS), platform as a service (PaaS) and software as a service (SaaS). Since the demand for cloud resources will change over time, setting a fixed amount of resources results in either over- or under-provisioning, so cloud service providers (CSPs) afford dynamic resources for a scalable workload, applying a pay-as-you-go cost model where clients only pay for the amount of resources they actually use. Cloud computing brings many advantages to the end user applications like high availability, flexibility, scalability, reliability, to mention a few.\\
%The \textit{National Institute of Standards and Technology} (NIST) defines cloud computing as a model for enabling ubiquitous, convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction \cite{mell2011nist}.
%IaaS allows cloud customers to directly accesses IT infrastructure for processing, storage, networking, over the Internet. Clients can configure the IaaS (often offered as a standalone VM), in terms of hardware (e.g., number of CPU cores, RAM capacity) and corresponding software for his need. PaaS offer users a framework they can build upon to develop or customize applications. It manages the underlying low-level processes and allows users to focus on managing software for its applications. Finally, SaaS is the most popular way of using cloud computing. It utilizes the internet to deliver applications to its users, which are managed by a third-party vendor. This service is helpful if the user likes to get full software packages, and do not want to take care of software issues, such as database scalability, socket management, etc.\\
%Cloud computing provides customers with yet another feature that they may use taking into account both security and configurability levels that their applications require, which includes private cloud, community cloud, public cloud, and hybrid cloud.\\
\noindent\tab Although cloud computing has brought forth many advantages, it has certain limitations. Since cloud servers reside in remote data centers, end-to-end communication may have long delays (characteristic of multi-hops transmissions over the Internet), so the time required to access cloud-based services may not be suitable for some applications with ultra-low latency requirements (real-time). Augmented reality applications that use head-tracked systems, for example, require end-to-end latencies to be less than 16 ms \cite{ellis2004generalizeability}. Cloud-based virtual desktop applications require end-to-end latency below 60 ms if they are to match QoS of local execution \cite{taylor2015virtual}. Remotely rendered video conference, on the other hand, demand end-to-end latency below 150 ms \cite{szigeti2005end}.\\
\noindent\tab Despite the fact that mobile devices have evolved radically in the last years, battery life, computation and storage capacity remain limited. This means that, heavy application executions must be offloaded to cloud servers, which then return processed results. The solution that has already been proposed is to bring the cloud closer to the end users, where entities such as base-stations would host smaller sized clouds. This idea has been variously termed as Cloudlets \cite{satyanarayanan2013cloudlets}, Fog Computing \cite{bonomi2012fog}, Edge Computing \cite{davy2014challenges}, and Follow Me Cloud \cite{taleb2013follow}, to name a few.\\
%Among those paradigms are \textit{Fog Computing} (FC), \textit{Mobile Computing} (MC), \textit{Mobile Cloud Computing} (MCC), \textit{Mobile Ad hoc Cloud Computing} (MACC), \textit{Edge Computing} (EC),\textit{ Multi-access Edge Computing} (MEC), \textit{Cloudlet Computing} (CC), \textit{Mist Computing} (mist) [survey].\\[6pt]
%Context - FOG COMPUTING
\noindent\tab Fog computing is a new computing architecture introduced in 2012 by Bonomi et al. \cite{bonomi2012fog}, that later, in 2015, big companies such as Cisco Systems, ARM Holdings, Dell, Intel, Microsoft, and Princeton University, founded the OpenFog Consortium, to promote interests and development in this field \cite{msv_2016}. It aims to enable computing, storage, networking, and data management not only in the cloud, but also along the cloud-to-thing path as data traverses to the cloud (preferably close to the IoT devices).
%OpenFog Consortium defines fog computing as a horizontal system-level architecture that distributes computing, storage, control and networking functions closer to the users along a cloud-to-thing continuum.
Fog nodes, also known as fog servers or cloudlets (smaller sized clouds with lower computational capacity), can be placed close to IoT source nodes, due to low hardware footprint and low power consumption (e.g., small servers, routers, switches, gateways, set-top boxes, access points). This allows latency to be much smaller, through geographical distribution, compared to traditional cloud computing. Nevertheless, cloud is still more suitable than fog for massive data processing. So even though, fog computing has been proposed to grant support for IoT applications, it does not replace the needs of cloud-based services. In fact, fog and cloud complement each other and one cannot replace the need of the other. Fog computing can be seen as a cloud computing extension, that uses a distributed cloud layer, composed of cloudlets, located closer to the users along a cloud-to-thing continuum and hence able to provide lower latencies than the cloud. Together they offer services even further optimized, allowing enhanced capabilities for data aggregation, processing, and storage, where cloudlets are fundamental to both improving latencies and reducing network traffic to the cloud. Moreover, Internet connectivity is not essential for the fog-based services to work, what means that services can work independently and send necessary updates to the cloud whenever the connection is available \cite{yousefpour2018all}.\\
%Motivation
\noindent\tab Fog computing will be crucial in a diversity of scenarios. For instance, heterogeneous sensory nodes (e.g., sensors, controllers, actuators) on a self-driving vehicle, are estimated to generate about 1 GB data per second \cite{angelica2013google}. As the number of features grow, the data deluge grows out of control. Moreover, this type of systems, where people's lives depends on it, are hard real-time what means that it is absolutely imperative that all deadlines are met. Offloading tasks to fog nodes will be the best solution, once a big effort in mobility support has been done through the migration of VMs using cloudlets \cite{lopes2017myifogsim}. Also, in this context, Puliafito et al. address three types of applications where fog is required, namely, citizen's healthcare, drones for smart urban surveillance and tourists as time travellers \cite{puliafito2017fog}, addressing the needs of low latency and mobility support. On top of that, the number of mobile devices are predicted to reach 11.6 billion by 2021, where the subset of IoT ones are expected to be 929 million \cite{cisco_2017}. With more and more devices sending data to the cloud, leads to and increasing bandwidth which is a bottleneck in terms of response time, where fog computing is the solution to prevent it.\\
%Zhang et al. shows another example of application where it is referred the massively multi-player online games (MMOGs) and virtual reality (VR) technologies, VR-MMOGs and the challenges associated with stringent latency, high bandwidth requirement and mobility large scale requirement for a large number of simultaneous players \cite{zhang2017towards}. 
%The problem
\noindent\tab Despite the benefits that fog promises to offer such as low latency, heterogeneity, scalability and mobility, the current model suffer from some limitations that still require further efforts to overcome them.\\
%These are related to a variety of features or objectives like QoS, Cost, Energy, Bandwidth, mobility to mention a few [survey].
%The problem - Multi-objective fog system design
\noindent\tab Fog servers are supposed to be closer to end devices so its location has to be ubiquitous, consequently, less powerful than clouds due to the high deployment cost. If many IoT devices make requests to the same fog node at the same time, it will not have enough computational and storage power to give a prompt response to them. So it raises the question of should a service currently running in one fog node be migrated to another one, and if yes, where? While conceptually simple, it is challenging to make this decisions in an optimal manner. Offloading tasks to the next server seams to be the solution, however, migrate the related data and processing, that initially was one-hop away to the end device to a multi-hop away server, will increase network distance, and consequently the response delay and bandwidth usage by the intermediate links. Besides, this decision still has to take into account the cost for both the client, with respect to the time spent in the migration, and the provider, in terms of costs and energy. Ignoring some of these parameters can lead to make incorrect decisions, what will both violate acceptable latency QoS constraints user's application and damage or defeat the credibility of fog computing.\\
%The problem - Mobile fog computing
\noindent\tab Another limitation, that are closely related to the aforementioned, is the lack of support for fog server's mobility. Following the idea of the previous issue, if there is no perfect or solution that met all the requirements, it rises the question of should a fog node be moved to provide offloading support to a overloaded fog node and leave the current area with less computing and storage capabilities, and if yes, where should it be placed?\\
%Another...  \cite{ye2016scalable} shows leverage the characteristics of buses and propose a scalable fog computing paradigm with servicing offloading in bus networks. As the above mentioned, there existis plenty of diferent ones so computing and data capacities should be maintained close to end devices to keep latencies as low as possible and mobility should be provided through VM migration.\\
%Alternatives \noindent\tab [Alternatives] ?? \\
%Our approach
\noindent\tab Summing up, we intend to tackle two of the current limitations which are, to the best of our knowledge, untreated problems in the literature. One is to provide support mobility in fog computing, not exclusively to the end devices but also to the fog nodes and the other is to achieve multi-objective fog system design.\\
\noindent\tab This research will, therefore, focus on (...)\\[50pt]
%Mobile fog computing -------
%Research Direction or Potential Solution: • Propose mobile fog computing, where fog nodes can move. • Scheme for management or federation of mobile fog nodes. • Provisioning method for mobile fog services to keep the service always-available for IoT nodes. • Design of mobility-aware task offloading and scheduling schemes when fog nodes are mobile. Related Features or Objectives: Mobility, Management Related Categories: Resource Discovery; Concepts and Frameworks using Fog; Programming Models and Data Modeling; Service Provisioning; Security and Privacy; Scheduling, offloading, and Load Balancing
%Multi-objective fog system design -------
%\subsubsection{Optimization algorithm on VM migration based on latency (optimização, devemos escolher, para já, a minimização do atraso)}
%balanço entre atraso de migração, atraso de comunicação e atraso de processamento
%Research Direction or Potential Solution: Propose schemes that consider multiple objectives (e.g., latency, bandwidth, energy) simultaneously (e.g., an efficient task offloading scheme that considers bandwidth, waiting time, availability, security, and energy). Related Features or Objectives: QoS, QoE, Cost, Energy, Bandwidth Related Categories: Resource Analysis and Estimation; Scheduling, offloading, and Load Balancing; Testbeds and Experiments
%Starting from available simulators a significant programming effort is required to obtain a simulation tool meeting the actual needs. (deve estar no trabalho a realizar, não na intro..)
%Contributions \noindent\tab [Contributions] ?? \\
%Road map
\noindent\tab The remainder of the document is structured as follows. Section \ref{sec:Goals} xxx. Section \ref{sec:RelatedWork} xxx. Section \ref{sec:Architecture} describes xxxx. Section \ref{sec:Evaluation} defines the xxx. Finally, Section \ref{sec:Schedule} presents xxxx and Section \ref{sec:Conclusion} xxxx.
%Rather than applying the Fog concept to a specific area, this paper is focused on the realization of Fog.
%Simply applying existing radio access-oriented MM (mobility management) schemes leads to poor performance mainly due to the co-provisioning of radio access and computing services of the MEC-enabled (mobile edge computing) BSs (base stations).
%More specifically, Fog might be specified in terms of functionality as Fog edge nodes (FENs), Fog server (FS), and Foglet, where FENs and FS are hardware nodes, and Foglet is the middleware in charge of data exchange, as presented in Fig. 1.