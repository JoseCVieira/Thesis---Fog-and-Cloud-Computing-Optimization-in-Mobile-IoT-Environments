%!TEX encoding = UTF-8 Unicode
\subsection{Migration Optimization in Mobile Fog Environments}
\label{sec:Migration}
\noindent When an IoT device needs to offload some heavy application to a third party, ideally it will be connected to the nearest server, securing an one-hop away fog server to ensure the shortest network delay. However, as their physical distance increases either by device or server movement, their network distance (i.e. the number of hops) will also increase. Hence, both latency and bandwidth usage by the intermediate links will increase, resulting in poor connectivity. This away, in such dynamic environments the decision-making of where to offload the work is a major concern. Moreover, even if both clients and servers are static, the end-to-end latency may increase due to unexpected crowds of mobile clients seeking to connect or making requests to the same fog server simultaneously, which may lead to QoS violations.\\
\noindent\tab In Section \ref{sec:fog_architecture} was verified that applications can be offloaded as a whole, or as a set of modules which may have different latency constraints. Regardless of their type, whenever it is justified the system needs to be readjusted. This is performed through the exchange of VMs or containers (containing the applications or modules) between fog nodes. For this reason, it is necessary to answer the following questions: \textit{When is this exchange justified? And what is the best placement for those applications and/or modules?} As stated in Section \ref{subsec:Objectives}, this work intends to implement multi-objective management decision-making in a novel architecture. Hence this state-of-the-art section intends to study some of the proposed mechanisms in the literature.

\subsubsection{Network Utilization-Aware}\label{NetworkUtilizationAware}
\noindent Minimization of network utilization is one of the main objectives of fog computing. In fact, fog appears to overcome this inherent limitation of cloud computing. Thus, besides guarantee QoS, namely the time boundaries of applications, it is also  important to reduce bandwidth usage. This utilization of network is essentially due to tree factors, the transmission of virtualized resources (VMs or containers), transmission of data between the client and the deployed application into the fog nodes, and control messages. If applications are deployed using DDF programming model, a fourth factor rises, the data transmission between modules. In this section, the reviewed literature propose models to mitigate the former, providing long term QoS, reducing the number of migrations.\\
\noindent\tab B. Ottenwälder et al. \cite{ottenwalder2013migcep} consider an environment with mobile devices and fixed fog nodes, where users offload real-time applications such as Complex Event Processing (CEP). CEP is a paradigm where changes in sensor measurements are modeled as events, while the application is modeled as set of event-driven operators. They state that each migration comes with a cost, consequence of the local state that also needs to be migrated along with the operators. Thus, frequent migration would significantly decrease the system performance. To overcome this limitation, they propose a placement and migration method for fog providers to support operator migrations in Mobile Complex Event Processing (MCEP) systems. Their method plans the migration ahead of time through knowledge of the MCEP system and predicted mobility patterns towards ensuring application-defined end-to-end latency restrictions and reducing the network utilization. These predicted mobility patterns were captured using three different methods: uncertain locations from the \textit{dead reckoning} approach (linear), certain locations that could stem from a \textit{navigation} system (navi), and \textit{learned} transitions between leaf broker (learned). This method, allows a minimization of migration costs by selecting migration targets that ensure a low expected network utilization for a sufficiently long time. Moreover, they present how the application knowledge of the CEP system can be used to improve current live migration techniques for VMs to reduce the required bandwidth during the migration (i.e. unnecessary events are not migrated). \\
\noindent\tab R. Urgaonkar et al. \cite{urgaonkar2015dynamic} argue that because of the uncertainty in user mobility and request patterns, it is challenging to make the decision in an optimal manner. Also, in this work is argued that methods which depend on mobility patterns have several drawbacks, namely: (1) it requires extensive knowledge of the statistics of the user mobility and request arrival processes that can be impractical to obtain in a dynamic network, (2) even when this is known, the resulting problem can be computationally challenging to solve, and (3) any change in the statistics would make the previous solution suboptimal and would require recomputing the optimal solution. Thus, they propose a new model, inspired by the technique of Lyapunov optimization, that overcomes these drawbacks (i.e. does not require any knowledge of the transition probabilities). The overall problem of dynamic service migration and workload scheduling to optimize system cost while providing end user performance guarantees is formulated as a sequential decision-making problem in the framework of Markov Decision Processes (MDPs). The cost depends on reconfiguration cost, inherent to migration services (i.e. moving the application from one cloudlet to another) and on transmission cost, time-average of user-to-cloudlet request routing that depends on their distance. They have developed a new approach for solving a class of constrained MDPs that possess a decoupling property. When this property holds, their approach enables the design of simple online control algorithms that do not require any knowledge of the underlying statistics of the MDPs.\\
\noindent\tab Also in this context, W. Zhang et al. \cite{zhang2016segue} state that previous studies have proposed a static distance-based MDP for optimizing migration decisions. However, these models fail to consider dynamic network and server states in migration decisions, assuming that all the important variables are known. Moreover, they also point out another unaddressed problem which lies in the recalculation time interval of the method. Since running MPD is a heavy computing task, a short recalculation interval introduces a considerable overhead to the server. On the other hand, a long recalculation interval may translate into lazy migration, resulting in periods of transgression of QoS guarantees. In order to overcome these issues, the authors propose SEGUE. This model achieves optimal migration decisions by providing a long-term optimal QoS to mobile users in the presence of link quality and server load variation. Additionally, SEGUE adopts a QoS aware scheme to activate the MDP model. In other words, it only activates the MDP model when QoS violation is predicted. Thus, it avoids unnecessary migration costs and bypass any possible QoS violations while keeping a reasonable low overhead in the servers. \\
\noindent\tab The work performed by Wuyang Zhang et al. \cite{zhang2017towards} use as case study the Massively Multiplayer Online Gamse (MMOGs) with Virtual Reality (VR) technologies, VR-MMOGs. They present the main challages of VR-MMOGs, namely: stringent latency, high bandwidth, and large scale requirements. This work shows one problem that remains unsolved: how to distribute the work among the user device, the fog nodes, and the center cloud to meet all three requirements especially when users are mobile. Their approach was to place local view change updates on fog nodes for immediate responses, frame rendering on fog nodes for high bandwidth, and global game state updates on the center cloud for user scalability. In this kind of games, users need to move, so in order to keep a low latency communication, they also propose an efficient service placement algorithm based on MDP. This method takes into account the presence of dynamic network states and server workload states, and user mobility providing long term QoS. To ensure feasibility of this method, they come up with an approach that reduces the algorithm complexity in both storage and execution time. Nonetheless, unlike many of the service migration solutions which assumes an ignorable service transition time, they point out that it is impossible to migrate an fog service from one fog to another instantly given the size of a VR game world. Therefore, they propose a mechanism to ensure a new fog node is activated when a player connects to the new one. \\[6pt]
\textit{Concluding Remarks} - The presented literature intends to reduce the number of migrations by providing long term QoS. This also reduces the downtime service, increasing QoS. While the first work, considers distributed applications, where the set of operators which are deployed among a set of fog nodes need some coordination in migrations, the rest consider applications as a whole. As already discussed, DDF programming model can bring advantages to fog computing. However the two latter works consider network state and server performance (resulting in workload) in their models. They all fail in not consider an energy consumption, a cost model and an environment where fog nodes can be movable.

\subsubsection{Energy-Aware}\label{EnergyAware}
\noindent In order to achieve the QoS objective, the placement of applications and their modules has often to be moved between different entities that compose the 3-tier architecture (things-fog-cloud) what evolves energetic costs. For instance, it is needed exchange control messages, communicate between modules placed at different nodes, change the module placement, etc. Thus, energy-aware must be an important factor to be taken into account in the decision making algorithm of \textit{when} and \textit{where} to offload work to another entity in order to increase fog infrastructure providers' profit.\\
\noindent\tab In this context, R. Deng et al. \cite{deng2016optimal} focused on investigating power consumption and network delay tradeoff in cloud-fog services. They formulate a workload allocation problem which suggests the optimal workload allocations between fog and cloud toward the minimal power consumption with the constrained service delay. This was performed trough the modeled power consumption function and delay function of each part of the fog-cloud computing system. It is worth noting that power consumption only considers energy consumption of work computation disregarding communication costs. The primal problem is then tackled using an approximate approach through decomposition, and formulate three subproblems of three corresponding subsystems. These subproblems can be solved via existing optimization techniques. \\
\noindent\tab Y. Xiao et al. \cite{xiao2017qoe} investigate two performance metrics for fog computing networks: mobile users’ QoS and fog nodes’ power efficiency. In their scheme fog nodes can process or offload to other fog nodes part of the workload that was initially sent to the cloud. Fog nodes decide to either offload the workload to neighbors or locally process it, under a given power constraint. A distributed optimization algorithm based on distributed Alternating Direction Method of Multipliers (ADMM) via variable splitting algorithm is proposed to achieve the optimal workload allocation solution that maximizes users’ QoS under the given power efficiency. In this work, power efficiency of each fog node is measured by the amount of power consumed by each fog node to offload each unit of workload from the cloud.\\
\noindent\tab C. Anglano et al. \cite{anglano2018profit} present the Online Profit Maximization (OPM) algorithm. It is an approximation algorithm that aims increasing the profit of fog infrastructure providers, by reducing the overall energy consumption of the infrastructure without a priori knowledge, and yet guarantee the QoS to its users. Their study considers mobile environments, where the end devices that are generating data are mobile.\\
\noindent\tab The work performed by A. Kattepur et al. \cite{kattepur2016resource} investigates the problem of computation offloading in fog computing. They present an energy model and communication costs with respect to computational offloading and formulate an optimal deployment strategy when dealing with distributed computation, while keeping energy and latency constraints in mind. The formulations are solved in Scilab using the Karmarkar linear optimization solver. They evaluate their approach in a sense-process-actuate model using a network of mobile robotic sensor-actuators developed in ROS/Gazebo.\\
\noindent\tab Y. Nan et al. \cite{nan2017adaptive} describe an online adaptive algorithm, Lyapunov Optimization on Time and Energy Cost (LOTEC), based on the technique of Lyapunov optimization. Their aim is to provide an energy-efficient data offloading mechanism to ensure minimization of long-term system cost (measured by the money spending on energy consumption) and yet guarantee that users do not experience a poor quality of service. This kind of problems, generally, can be converted into a constrained stochastic optimization problem. LOTEC is a quantified near optimal solution and is able to make control decision on application offloading by adjusting the two-way tradeoff. This decision-making distributes the incoming applications to the corresponding tiers without a priori knowledge of the status of users and system. In addition, their proposed algorithm achieves the average response time arbitrarily close to the theoretical
optimum. \\[6pt]
\textit{Concluding Remarks} - The above works aim to minimize the energy consumption of fog infrastructure providers. To this end they present efficient mechanisms regarding to offloading work in an energy-efficient manner while guarantee QoS to its users. Once again their models do not consider mobile fog nodes nor DDF programming model. Besides, these do not formulate a specific cost model or only consider energy consumption being its only variable.

\subsubsection{Cost-Aware}
\noindent As aforementioned besides guarantee QoS to its users, fog service providers also need to maximize their profit. Hence is important to develop an accurate cost model in order to accept and implement fog computing. Besides, similarly to what cloud does, fog has to implement a pay-as-you-go cost model in order to provide services on-demand to its users, without under- or over-provisioning, and charging a fair price. To this end, the cost model needs to apply a communication model, an energy model, and a resource utilization model.\\
\noindent\tab In this context, L. Gu et al. \cite{gu2017cost} state the importance of fog computing in medical cyber-physical systems as the number of users grows. In order to tackle the cost-efficiency problem in this kind of systems, they argue that communication Base Station (BS) association, task distribution and VM deployment are all critical. Therefore, in this paper, the authors jointly study these three issues towards minimizing the overall cost while satisfying the QoS requirement. They formulate the cost minimization problem in a form of Mixed-Integer NonLinear Programming (MINLP) with joint consideration of communication BS association, subcarrier allocation, computation BS association, VM deployment and task distribution. To tackle the high computational complexity of solving this problem, they linearize it into a Mixed-Integer Linear Programming (MILP) problem. This way they are able to solve the optimal programming model using solvers such as CPLEX and Gurobi. However, it is still time consuming due to the existence of a large number of integer variables. To this end, they further propose an LP-based two-phase heuristic algorithm. It is worth noting that this work explores placement of VMs in fog computing, whereas it does not tackle this problem in mobile environments, disregarding both users and servers mobility, consequently not addressing the inherit migration problems.\\
\noindent\tab Unlike the previous one, this work considers mobility of users. However, similarly the aim of L. Yang et al. \cite{yang2016cost} is to guarantee QoS to mobile users, minimizing the average latency of all the users’ request loads, while minimizing the overall costs of service providers. The latter, is composed by minimization of both resource usage on cloudlets and service placement transitions. The authors state that this three way trade-off is a difficult problem. Moreover, the request load could vary significantly and frequently in both spatial and temporal domain due to the mobility of users. Such dynamic request load implies a periodic update of decisions, keeping in mind both the current performance and affordable cost, and the expected future workload. In order to solve this tree way trade-off, the authors first formulate the snapshot problem, named Basic Service Placement Problem (BSPP), which aims to optimize the access latency with the capacity constraints of cloudlets. As it is hard to solve, they design a competitive heuristic to BSPP which outperforms a set of benchmark algorithms significantly in terms of the access latency, and algorithm run time. Further, they also extend BSPP to a more practical model that aims to optimize the trade-off between access latency, resource usage and service placement transitions. Finally they develop an online algorithm for this model that can be deployed directly in practical systems. It is worth noting that their solution utilizes user’s mobility pattern and services access pattern to predict the distribution of user’s future requests, and then adapt the service placement and load dispatching online based on the prediction. Their work does not consider DDF programming model, an energy model nor mobility of fog nodes.\\
\noindent\tab O. Skarlat et al. \cite{skarlat2017optimized} start by describing a conceptual framework for resource provisioning and service placement in fog. They consider the concept of fog colonies, micro-data centers made up from an arbitrary number of fog cells. Within a fog colony, services and data can be distributed and shared between the single cells, leading to a cooperative execution of IoT applications (DDF programming model). Based on this concept, their work, formalizes an optimization problem that aims to adhere to the deadlines on deployment and execution time of applications and to maximize the utilization of existing resources in fog, rather than in cloud, leading to lower execution cost. To solve this placement problem, they apply different approaches, namely the exact optimization method and its approximation through a greedy first fit heuristic and a genetic algorithm. They also compare the results, in the fog simulation toolkit iFogSim, to a classical approach that neglects fog resources and runs all services in a centralized cloud. The goal of the evaluation is to identify the best approach to solve the proposed optimization problem in terms of resulting QoS, QoS violations, and cost. This work does not provide mobility mechanisms, not addressing the inherit migration problems nor communication energetic/monetary costs. \\
\noindent\tab L. Wang et al. \cite{wang2018service} address the social VR applications to study the problem of placing service entities (VMs deployed) in fog environments. Although motivated by VR applications, the authors state that this problem is fundamental for any applications that require interactions between either user and the respective VM or user and VMs of other users. The placement problem is to decide where to place the service entity of each user among the cloudlets in order to achieve economic operations of the cloudlets as well as satisfactory QoS for the users. This problem is is non-trivial due to the following challenges: (1) cloudlets are heterogeneous, (2) VMs need to exchange metadata frequently with the associated users and other VMs (of other users), due to the type of application in cause, and (3) due to the fact that cloudlets are not intentionally designed to simultaneously accommodate a large number of VMs, especially for VR applications where specific hardware such as GPU may be involved, resource contention needs to be controlled. The authors model the aforementioned challenges with four types of cost: activation cost, the placement cost, the proximity cost, and the collocation cost. The considered cost models are comprehensive yet practical, and are general enough to capture a wide range of concrete performance measures in reality. They formulate the problem as a combinatorial optimization, which is NP-hard. To solve the problem, they propose ITerative Expansion Moves (ITEM) algorithm, a novel algorithm based on iteratively solving a series of minimum graph cuts. The algorithm is flexible and is applicable in both offline and online cases. It is worth noting that in this case there is only one VM deployed to the fog per application (i.e. the concept of DDF is not applied in this work). Also it does not consider any specific energy model.\\
\noindent\tab The work performed by T. Bahreini et al. \cite{bahreini2017efficient} also addresses multi tier placement (DDF programming model). The authors formulate the Multi-Component Application Placement Problem (MCAPP). Their objective is to find a mapping between components and servers, such that the total placement cost is minimized. This cost is composed of four types of costs at each time slot: (1) the cost of running one component in a specific server, (2) cost of relocating one component from one server to another, (3) communication cost between one component and the user, and (4) communication between components. With the objective to minimize the overall cost incurred when running the application, they we formulated the offine version of the problem as a Mixed Integer Linear Program (MILP) and then developed a heuristic algorithm for solving the online version of the problem. The algorithm is based on an iterative matching process followed by a locals search phase in which the solution quality is improved. This way they use simple algorithmic techniques, avoiding complex approaches such as those based on MDPs. They state that the proposed algorithm has low complexity and adds a negligible overhead to the execution of the applications. Although this work considers the location of servers in the estimation of cost (2), it does not consider an environment with mobile fog nodes.\\
\noindent\tab The study performed by X. Sun et al. \cite{sun2016primal} presents, similarly to the previous ones, a case scenario where end devices are mobile. To preform this work they use a cloudlet network architecture to bring the computing resources from the centralized cloud to the edge. They present the PRofIt Maximization Avatar pLacement (PRIMAL) strategy. PRIMAL maximizes the trade-off between the migration gain (i.e. the end-to-end delay reduction) and the migration cost (i.e. the migration overheads), selectively migrating the avatars (a software clone located in a cloudlet) to their optimal locations.\\
\noindent\tab A different approach was taken by D. Ye et al. \cite{ye2016scalable}. They leverage the characteristics of buses and propose a scalable fog computing paradigm with servicing offloading in bus networks. Knowing that buses have fixed mobility trajectories and strong periodicity, they consider a fog computing paradigm with service offloading in bus networks which is composed by two parts: roadside cloudlets and bus fog servers. The roadside cloudlet consists of three components: dedicated local servers, location-based service (LBS) providers, access points (APs). The dedicated local servers virtualize physical resource and act as a potential cloud computing site. The LBS providers offer the real time location of each bus in bus networks. The APs act as gateways for mobile users and bus fog servers within the communication coverage to access the roadside cloudlet. When users need to offload some computationally intensive and delay sensitive tasks, they access APs and use the computing service of the roadside cloudlet. However, as cloudlets have limited computational and storage resources, they may became overloaded. The bus fog server is a virtualized computing system on bus, which is similar to a light-weight cloudlet server. Hence, those buses not only provide fog computing services for the mobile users on bus, but also are motivated to accomplish the computation tasks offloaded by roadside cloudlets. This allocation strategy is accomplished using genetic algorithm (GA), where the objective is to minimize the cost that roadside cloudlets spend to offload their computation tasks. Meanwhile, the user experience of mobile users are maintained. Although this work refers to mobile users, its meaning is not literal (representing the workload of both the buses and the roadside cloudlets), being supported only the mobility of fog servers. \\[6pt] %In their problem formulation there are two types of mobile users. On one hand there are mobile users that already have offloaded their computing tasks to the roadside cloudlets (i.e. representing the workload of the cloudlets). On the other hand there are several mobile users inside the bus that have also offloadded their tasks (i.e. representing the workload of bus fog servers).
\textit{Concluding Remarks} - Cost-aware is the most comprehensive and addressed in the literature. Unlike Section \ref{NetworkUtilizationAware} and Section \ref{EnergyAware} that treat singular problems, these works are much closer that what this work wants to implement. However, these works do not consider all necessary variables to implement a good and realistic fog placement model. For instance, none of them address the mobility of both end devices and fog nodes. Some of them do not consider DDF programming model. Also, most of the works penalize migration, and considers that since QoS is being guaranteed, there is no need to migrate applications/modules, but as network distance increases, the bandwidth usage by the intermediate links also increases, thus this trade-off needs to be carefully implemented. 

\subsubsection{Handover}
\noindent\tab X. Sun et al. \cite{sun2017avaptive} shows an architecture where each User Equipment (UE) has its own Avatar (a private computing and storage resources for the UE) which is deployed to a cloudlet, being the communication characterized by low end-to-end (E2E) latency. When UEs roam away, in order to maintain the end-to-end latency, their Avatars should be handed off among cloudlets accordingly. However, moving such amount of data (the Avatar’s virtual disk) during the handoff time may both incur unbearable migration time and network congestion. In order to overcome those limitations, they propose LatEncy Aware Replica placemeNt (LEARN) algorithm to place a number of replicas of each Avatar’s virtual disk into suitable cloudlets. Meanwhile, by considering the capacity limitation of each cloudlet, they propose the LatEncy aware Avatar hanDoff (LEAD) algorithm to place
UEs’ Avatars among the cloudlets such that the average E2E delay is minimized.\\ %nao sei se devia estar aqui!
\cite{bao2017follow}
The authors observe that traditional mobile network handover mechanisms cannot handle the demands of fog computation resources and the low-latency requirements of mobile IoT applications. The authors propose Follow Me Fog framework to guarantee service continuity and reduce latency during handovers. The key idea proposed is to continuously monitor the received signal strength of the fog nodes at the mobile IoT device, and to trigger pre-migration of computation jobs before disconnecting the IoT device from the existing fog node.\\
\cite{ma2017efficient}
Present a novel service handoff system which seamlessly migrates offloading services to the nearest edge server, while the mobile client is moving. Service handoff is achieved via container migration. They have identified an important performance problem during Docker container migration, proposing a migration method which leverages the layered storage system to reduce file system synchronization overhead, without dependence on the distributed file system.\\
\cite{sun2017emm}
Develop a novel user-centric energy-aware mobility management (EMM) scheme, in order to optimize the delay, under energy consumption constraint of the user. Based on Lyapunov optimization and multi-armed bandit theories, EMM works in an online fashion. Theoretical analysis explicitly takes radio handover and computation migration cost into consideration and proves a bounded deviation on both the delay performance and energy consumption compared with the oracle solution with exact and complete future system information. The proposed algorithm also effectively handles the scenario in which candidate BSs randomly switch ON/OFF during the offloading process of a task.\\
\cite{bi2018mobility}
Study of mobility support issue in fog computing for guaranteeing service continuity. Propose a novel SDN enabled architecture that is able to facilitate mobility management in fog computing by decoupling mobility management and data forwarding functions. Design an efficient handover scheme by migrating mobility management and route optimization logic to the SDN controller. By employing link layer information, the SDN controller can pre-compute the optimal path by estimating the performance gain of each path.\\
\cite{farris2017optimizing}
To guarantee the strict latency requirements, new solutions are required to cope with the user mobility in a distributed edge cloud environment. The use of proactive replication mechanism seems promising to avoid QoE degradation during service migration between different edge nodes. However, accounting for the limited resources of edge micro data-centers, appropriate optimization solutions must be developed to reduce the cost of service deployment, while guaranteeing the desired QoE. In this paper, Ivan Farris et al., by leveraging on prediction schemes of user mobility patterns, have proposed two linear optimization solutions for replication-based service migration in cellular 5G networks: the min-RM approach aims at minimizing the QoE degradation during user handover; min-NSR approach favors the reduction of service replication cost. Simulation results proved the efficiency of each solution in achieving its design goal and provides useful information for network and service orchestrators in next-generation 5G cloud-based networks.
%\noindent\tab Fog computing will be crucial in a diversity of scenarios. For
%instance, heterogeneous sensory nodes (e.g., sensors, controllers, actuators)
%on a self-driving vehicle, are estimated to generate about 1GB data per second
%\cite{angelica2013google}. As the number of features grow, the data deluge
%grows out of control. Moreover, these types of systems, where people's lives
%depends on it, are hard real-time what means that it is absolutely imperative
%that all deadlines are met. Offloading tasks to fog nodes will be the best
%solution, once a big effort in mobility support has been done through the
%migration of VMs using cloudlets \cite{lopes2017myifogsim}. Also, in this
%context, Puliafito et al. address three types of applications where fog is
%required, namely, citizen's healthcare, drones for smart urban surveillance and
%tourists as time travellers \cite{puliafito2017fog}, addressing the needs of
%low latency and mobility support.\\

%%Previous reactive load balancing algorithms migrate VMs upon the occurrence of load imbalance, while previous proactive load balancing algorithms predict PM overload to conduct VM migration
% another works were performd using MDP-based approaches (ex. Distributed Autonomous Virtual Resource Management in Datacenters Using Finite-Markov Decision Process)