%!TEX encoding = UTF-8 Unicode
\section{Migration Optimization in Mobile Fog Environments}
\label{sec:Migration}
When an IoT device needs to offload some heavy application to a third party, ideally it will be connected to the nearest server, securing a hop away fog server to ensure the shortest network delay. However, as their physical distance increases either by device or server movement, their network distance (i.e. the number of hops) will also increase. Hence, both latency and bandwidth usage by the intermediate links will increase, resulting in poor connectivity. This away, in such dynamic environments the decision-making of where to offload the work is a major concern. Moreover, even if both clients and servers are static, the end-to-end latency may increase due to unexpected crowds of mobile clients seeking to connect or making requests to the same fog server simultaneously, which may lead to QoS violations.\\
\noindent\tab In Section \ref{sec:fog_architecture} was verified that applications can be offloaded as a whole, or as a set of modules which may have different latency constraints. Regardless of their type, whenever it is justified the system needs to be readjusted. This is performed through the exchange of VMs or containers (containing the applications or modules) between fog nodes. For this reason, it is necessary to answer the following questions: \textit{When is this exchange justified? And what is the best placement for those applications and/or modules?} As stated in Section \ref{subsec:Objectives}, this work intends to implement multi-objective management decision-making in a novel architecture. Hence, this state-of-the-art section intends to study some proposed mechanisms in the literature.

\subsection{QoS-Aware}\label{sec:QoS}
The first objective that fog computing has to guarantee is QoS. When users outsource some delay constrained task or application, they expect fog to be adaptive enough so that they can move while their time boundaries are met. Without this objective fog computing is useless once it appears, in part, to help cloud computing to overcome this limitation.\\
%OK
\noindent\tab In this context, the work performed by T. Rodrigues \cite{rodrigues2017pso} et al. is focused on lowering the transmission delay and processing delay. On the one hand, the transmission delay encompass the time spent to send the data/task to the cloudlet and the time interval to receive the results. On the other hand, processing delay regards to the time that the work spends in the cloudlet's work queue and the respective time to being processed. Their goal is to lower service delay providing QoS to all applications. In order to optimize the formulated problem, is applied a Particle Swarm Optimization (PSO) model. Their architecture assumes the presence of a central office which is responsible for collecting all information about static users and cloudlets physical locations and then execute the PSO model. It is worth noting that in their approach, the delay of VM migrations is not considered. Also, does not specify what is the optimal frequency of execution of the algorithm.\\
%OK
\noindent\tab The study performed by X. Sun et al. \cite{sun2016primal} presents, a case scenario where the end devices are mobile. To perform this work they use a cloudlet network architecture to bring the computing resources from the centralized cloud to the edge. They present the PRofIt Maximization Avatar pLacement (PRIMAL) strategy. PRIMAL maximizes the trade-off between the migration gain (i.e. the end-to-end delay reduction) and the migration cost (i.e. the migration overheads incured in the avatar, which compromise its performance), by migrating the avatars (a software clone located in a cloudlet) to their optimal locations, using  pre-copy live migration. To solve the formulated problem, they use the Mixed-Integer Quadratic Programming tool in the CPLEX solver to find the heuristic solution of PRIMAL.\\
%R. Urgaonkar et al. \cite{urgaonkar2015dynamic} argue that because of the uncertainty in user mobility and request patterns, it is challenging to make migration decisions in an optimal manner. Also, in this work is argued that methods which depend on mobility patterns have several drawbacks, namely: (1) they require extensive knowledge of the statistics of the user mobility and request arrival processes that can be impractical to obtain in a dynamic network, (2) even when this is known, the resulting problem can be computationally challenging to solve, and (3) any change in the statistics would make the previous solution suboptimal and would require recomputing the optimal solution. Thus, they propose a new model, inspired by the technique of Lyapunov optimization, that overcomes these drawbacks (i.e. does not require any knowledge of the transition probabilities). The overall problem of dynamic service migration and workload scheduling to optimize system cost while providing end user performance guarantees is formulated as a sequential decision-making problem in the framework of Markov Decision Processes (MDPs). The cost depends on reconfiguration cost, inherent to migration services (i.e. moving the application from one cloudlet to another) and on transmission cost (i.e. time-average of user-to-cloudlet request routing) which depends on their distance. Their goal is to design a control algorithm for making request routing decisions so that the time-average overall transmission and reconfiguration costs are minimized while serving all requests with finite delay. They have developed a new approach for solving a class of constrained MDPs that possess a decoupling property. When this property holds, their approach enables the design of simple online control algorithms that do not require any knowledge of the underlying statistics of the MDPs.

\subsection{Bandwidth-Aware}\label{sec:bandwidth}
Minimization of network utilization is one of the main objectives of fog computing. In fact, fog appears to overcome this inherent limitation of cloud computing. Thus, besides guarantee QoS, it is also  important to reduce bandwidth usage. This utilization of network is essentially due to three factors: the transmission of virtualized resources (VMs or containers) which contain the applications/modules, transmission of data between the end device and the deployed application into the fog nodes, and control messages exchanged between fog nodes. If the applications are deployed using DDF programming model a fourth factor rises, the data transmission between modules. In this section, the reviewed literature propose models to mitigate bandwidth usage providing long-term QoS, reducing the number of migrations.\\
%
\noindent\tab B. Ottenw√§lder et al. \cite{ottenwalder2013migcep} consider an environment with mobile devices and fixed fog nodes, where users offload real-time applications such as Complex Event Processing (CEP). CEP is a paradigm where changes in sensor measurements are modeled as events, while the application is modeled as set of event-driven operators. They state that each migration comes with a cost, consequence of the local state that also needs to be migrated along with the operators. Thus, frequent migration would significantly decrease the system performance. To overcome this limitation, they propose a placement and migration method for fog providers to support operator migrations in Mobile Complex Event Processing (MCEP) systems. Their method plans the migration ahead of time through knowledge of the MCEP system and predicted mobility patterns towards ensuring application-defined end-to-end latency restrictions and reducing the network utilization. These predicted mobility patterns were captured using three different methods: uncertain locations from the \textit{dead reckoning} approach (linear), certain locations that could stem from a \textit{navigation} system (navi), and \textit{learned} transitions between leaf broker (learned). This method allows a minimization of migration costs by selecting migration targets that ensure a low expected network utilization for a sufficiently long time.\\ %Moreover, they present how the application knowledge of the CEP system can be used to improve current live migration techniques for VMs to reduce the required bandwidth during the migration (i.e. unnecessary events are not migrated).\\
%OK1
\noindent\tab Also in this context, W. Zhang et al. \cite{zhang2016segue} state that previous studies have proposed a static distance-based MDP for optimizing migration decisions. However, these models fail to consider dynamic network and server states in migration decisions, assuming that all the important variables are known. Moreover, they also point out another unaddressed problem which lies in the recalculation time interval of the method. Since running MPD is a heavy computing task, a short recalculation interval introduces a considerable overhead to the server. On the other hand, a long recalculation interval may translate into lazy migration, resulting in periods of transgression of QoS guarantees. In order to overcome these issues, the authors propose SEGUE. This model achieves optimal migration decisions by providing a long-term optimal QoS to mobile users in the presence of link quality and server load variation. Additionally, SEGUE adopts a QoS aware scheme to activate the MDP model. In other words, it only activates the MDP model when QoS violation is predicted. Thus, it avoids unnecessary migration costs and bypasses any possible QoS violations while keeping a reasonable low overhead in the servers. The QoS prediction module assumes that mobile location, follows the one dimensional mobility pattern. The problem formulation is then formulated as a cost-reward between the predicted long term QoS improvement and the service downtime.\\
%The work performed by Wuyang Zhang et al. \cite{zhang2017towards} use as case study the Massively Multiplayer Online Gamse (MMOGs) with Virtual Reality (VR) technologies, VR-MMOGs. They present the main challenges of VR-MMOGs, namely: stringent latency, high bandwidth, and large scale requirements. This work shows one problem that remains unsolved: how to distribute the work among the user device, the fog nodes, and the center cloud to meet all three requirements especially when users are mobile. Their approach was to place local view change updates on fog nodes for immediate responses, frame rendering on fog nodes for high bandwidth, and global game state updates on the center cloud for user scalability. In this kind of game, users need to move, so in order to keep a low latency communication, they also propose an efficient service placement algorithm based on MDP. This method takes into account the presence of dynamic network states and server workload states, and user mobility providing long-term QoS. To ensure feasibility of this method, they come up with an approach that reduces the algorithm complexity in both storage and execution time. Nonetheless, unlike many of the service migration solutions which assumes an ignorable service transition time, they point out that it is impossible to migrate a fog service from one fog to another instantly given the size of a VR game world. Therefore, they propose a mechanism to ensure a new fog node is activated when a player connects to the new one.
%\\ \textit{Concluding Remarks} - The presented literature intends to reduce the number of migrations by providing long term QoS. This also reduces the downtime service, increasing QoS. While the first work, considers distributed applications, where the set of operators which are deployed among a set of fog nodes need some coordination in migrations, the rest consider applications as a whole. As already discussed, DDF programming model can bring advantages to fog computing. However the two latter works consider network state and server performance (resulting in workload) in their models. They all fail in not consider an energy consumption, a cost model and an environment where fog nodes can be movable.

\subsection{Energy-Aware}\label{sec:energy}
In order to achieve the QoS objective, the placement of applications and their modules has often to be moved between different entities that compose the 3-tier architecture (things-fog-cloud) which evolves energetic costs. For instance, it is needed to exchange control messages, communicate between modules placed at different nodes, change the module placement, etc. Thus, energy-aware must be an important factor to be taken into account in the decision making algorithm of \textit{when} and \textit{where} to offload work to another entity in order to minimize fog infrastructure providers' cost.\\
%OK1
\noindent\tab In this context, R. Deng et al. \cite{deng2016optimal} focused on investigating system power consumption and network delay trade-off in cloud-fog services. They formulate a workload allocation problem, which suggests the optimal workload allocations between fog and cloud toward the minimal power consumption with the constrained service delay. This was performed through the modeled power consumption and delay functions of each part of the fog-cloud computing system. It is worth noting that power consumption only considers energy consumption of work computation, disregarding communication costs. The problem is then tackled using an approximate approach through decomposition, and formulation of three subproblems, being solved through existing optimization techniques. This work also does not considers dynamic environments. All variables are static including the position of fog nodes and end devices. Also there is no cooperation between fog nodes. Similarly to the majority of the presented works, the decision-making is performed in a centralized manner.\\
%OK1
\noindent\tab Y. Xiao et al. \cite{xiao2017qoe} investigate two performance metrics for fog computing networks: the QoS of mobile users and the power efficiency of fog nodes. In their scheme, fog nodes can process or offload to other fog nodes part of the workload that was initially sent to the cloud. Fog nodes decide whether to offload the workload to neighbors or locally process it, under a given power constraint. A distributed optimization algorithm based on Alternating Direction Method of Multipliers (ADMM) via variable splitting is proposed. This allows to achieve the optimal workload allocation solution that maximizes QoS of users under the given power efficiency. In this work, power efficiency of each fog node is measured by the amount of consumed energy to offload each unit of workload from the cloud.\\
%\noindent\tab C. Anglano et al. \cite{anglano2018profit} present the Online Profit Maximization (OPM) algorithm. It is an approximation algorithm that aims to increase fog infrastructure providers' profit, by reducing the overall energy consumption of the infrastructure without a priori knowledge, and yet guarantee the QoS to its mobile end users. This cost is the sum of energy costs inherited from the execution of applications, cloning and migrating the VMs, turning on and off the fog nodes, and monetary penalties for QoS violations. To solve the formulated problem, their work applies an online optimization algorithm in each recalculation time interval, achieving near optimal solutions.\\(TEM CLONES E DEVIA ESTAR NO CUSTO)
%\noindent\tab The work performed by A. Kattepur et al. \cite{kattepur2016resource} investigates the problem of computation offloading in fog computing. They present an energy model and communication costs with respect to computational offloading and formulate an optimal deployment strategy when dealing with distributed computation, while keeping energy and latency constraints in mind. The formulations are solved in Scilab using the Karmarkar linear optimization solver. They evaluate their approach in a sense-process-actuate model using a network of mobile robotic sensor-actuators developed in Robot Operating System (ROS)/Gazebo.(PEERS ROBOT/FOG NODE)\\
%OK1
\noindent\tab Y. Nan et al. \cite{nan2017adaptive} describe an online adaptive algorithm, Lyapunov Optimization on Time and Energy Cost (LOTEC), based on the technique of Lyapunov optimization. Their aim is to provide an energy-efficient data offloading mechanism to ensure minimization of long-term system cost (measured by the money spending on energy consumption) and yet guarantee that users do not perceive a poor QoS. In general, this kind of problem can be converted into a constrained stochastic optimization problem. LOTEC is a quantified near optimal solution and is able to make control decision on application offloading by adjusting the two-way trade-off. This decision-making distributes the incoming applications to the corresponding tiers without a priori knowledge of users and system status.

\subsection{Cost-Aware}\label{sec:cost}
As aforementioned, besides guarantying QoS to its users, fog service providers also need to maximize their profit. Hence, it is important to develop an accurate cost model in order to accept and implement fog computing. Besides, similarly to what cloud does, fog has to implement a pay-as-you-go cost model in order to provide services on-demand to its users, without under- or over-provisioning, and charging a fair price. To this end, the cost model needs to apply a communication model, an energy model, and a resource utilization model.\\
%OK1
\noindent\tab In this context, L. Gu et al. \cite{gu2017cost} state the importance of fog computing in medical cyber-physical systems as the number of users grows. They state that different infrastructure service providers may apply different charging policies. Therefore, in this paper, the authors aim to minimize the overall resource management cost while satisfying the QoS requirements. They formulate the cost minimization problem in a form of Mixed-Integer NonLinear Programming (MINLP) with joint consideration of communication BS association, subcarrier allocation, computation BS association, VM deployment and task distribution. To tackle the high computational complexity of solving this problem, they linearize it into a Mixed-Integer Linear Programming (MILP) problem. This way they are able to solve the optimal programming model using solvers such as CPLEX and Gurobi. However, it is still time-consuming due to the existence of many integer variables. To this end, they further propose an LP-based two-phase heuristic algorithm. It is worth noting that this work explores placement of VMs in fog computing, whereas it does not tackle this problem in mobile environments, disregarding both users and servers mobility, consequently not addressing the inherent migration problems.\\
%OK1
\noindent\tab Unlike the previous one, this work considers mobility of users. However, similarly, the aim of L. Yang et al. \cite{yang2016cost} is to guarantee QoS to mobile users, minimizing the average latency of all the users‚Äô request loads, while minimizing the overall costs of service providers. The latter is composed by minimization of both resource usage on cloudlets and service placement transitions. The authors state that this three-way trade-off is a difficult problem. Moreover, the request load could vary significantly and frequently in both spatial and temporal domain due to the mobility of users. Such dynamic request load implies a periodic update of decisions, keeping in mind both the current performance and the expected future workload (using user‚Äôs mobility pattern and services access pattern to predict the distribution of user‚Äôs future requests). In order to solve this three way trade-off, the authors first formulate the snapshot problem, named Basic Service Placement Problem (BSPP), which aims to optimize the access latency with the capacity constraints of cloudlets. As it is hard to solve, they design a competitive heuristic to BSPP which outperforms a set of benchmark algorithms. It is worth noting that this work does not consider DDF programming model, an energy model nor mobility of fog nodes.\\%TIME SLOT = 10 MIN
%OK1OK
\noindent\tab O. Skarlat et al. \cite{skarlat2017optimized} start by describing a conceptual framework for resource provisioning and service placement in fog. They consider the concept of fog colonies (refer to Section \ref{sec:fog_arch_orchestration}) using a cooperative execution of IoT applications (DDF programming model). Based on this concept, their work, formalizes an optimization problem that aims to adhere to the deadlines on deployment and execution time of applications and to maximize the utilization of existing resources in fog, rather than in cloud, leading to lower execution cost. To solve this placement problem, they apply different approaches, namely the exact optimization method and its approximation through a greedy first fit heuristic and a Genetic Algorithm (GA). They also compare the results, in the fog simulation toolkit iFogSim, to a classical approach that neglects fog resources and runs all services in a centralized cloud. The goal of the evaluation is to identify the best approach to solve the proposed optimization problem in terms of resulting QoS, QoS violations, and cost. The latter is composed only by the execution costs in cloud infrastructures, neglecting execution costs in fog nodes. This work does not provide mobility mechanisms, not addressing the inherent migration problems.\\
%OK1
\noindent\tab L. Wang et al. \cite{wang2018service} address the social VR applications to study the problem of placing VMs deployed in fog environments such that, the total cost in the overall cost in the fog system is minimized. Although motivated by VR applications, the authors state that this problem is fundamental for any applications that require interactions between either mobile user and the respective VM or user and VMs of other users. The placement problem is to decide where to place the service entity of each user among the cloudlets in order to achieve economic operations of cloudlets as well as QoS. This problem is non-trivial due to the following challenges: (1) cloudlets are heterogeneous in terms of activation and running costs, (2) VMs need to exchange metadata frequently with the associated users and other VMs (of other users), and (3) due to the fact that cloudlets are not intentionally designed to simultaneously accommodate many VMs, especially for VR applications where specific hardware such as GPU may be involved, resource contention needs to be controlled. The authors model the aforementioned challenges with four types of cost: activation cost, the placement cost, the proximity cost, and the collocation cost. They formulate the problem as a combinatorial optimization, which is NP-hard. To solve the problem, they propose ITerative Expansion Moves (ITEM) algorithm, a novel algorithm based on iteratively solving a series of minimum graph cuts. The algorithm is flexible and is applicable in both offline and online cases. It is worth noting that the concept of DDF is not applied in this work nor considers any specific energy model.\\
%OK1
\noindent\tab The work performed by T. Bahreini et al. \cite{bahreini2017efficient} also addresses multi-tier placement (DDF programming model). The authors formulate the Multi-Component Application Placement Problem (MCAPP). Their objective is to find a mapping between components and servers, such that the total placement cost is minimized. This cost is composed of four types of costs at each time slot: (1) the cost of running one component in a specific server, (2) cost of relocating one component from one server to another, (3) communication cost between one component and the user, and (4) communication between components. With the objective to minimize the overall cost incurred when running the application, they formulate the offine version of the problem as a Mixed Integer Linear Program (MILP) and then developed a heuristic algorithm for solving the online version of the problem. The algorithm is based on an iterative matching process followed by a locals search phase in which the solution quality is improved. This way they use simple algorithmic techniques, avoiding complex approaches such as those based on MDPs. They state that the proposed algorithm has low complexity and adds a negligible overhead to the execution of the applications. Although this work considers the location of servers in the estimation of cost (2), it does not consider an environment with mobile fog nodes.\\
%
\noindent\tab A different approach was taken by D. Ye et al. \cite{ye2016scalable}. They leverage the characteristics of buses and propose a scalable fog computing paradigm with servicing offloading in bus networks. Knowing that buses have fixed mobility trajectories and strong periodicity, they consider a fog computing paradigm with service offloading in bus networks which is composed by roadside cloudlets and bus fog servers. The roadside cloudlet consists of three components: dedicated local servers, location-based service (LBS) providers, access points (APs). The dedicated local servers virtualize physical resources and act as a potential cloud computing site. LBS providers offer the real time location of each bus in bus networks. APs act as gateways for mobile users and bus fog servers within the communication coverage to access the roadside cloudlet. As cloudlets have limited computational and storage resources, they may become overloaded. The bus fog server is a virtualized computing system on bus, which is similar to a light-weight cloudlet server. Hence, those buses not only provide fog computing services for the mobile users on bus, but also are motivated to accomplish the computation tasks offloaded by roadside cloudlets. This allocation strategy is accomplished using GA, where the objective is to minimize the cost that roadside cloudlets spend to offload their computation tasks. Although this work refers to mobile users, its meaning is not literal (representing the workload of both buses and cloudlets), being supported only the mobility of fog servers.

\subsection{Multi-Objective}\label{sec:multi}
Unlike the previous sections, the current one aims to present works that were intended to study multi-objective optimization migration algorithms, rather that single or dual objective.\\
%OK
\noindent\tab Motivated by the trade-off between local execution power consumption and the offloading delay, the work performed by L. Liu et al. \cite{liu2018multiobjective} has the objective of minimize energy consumption, delay, and payment cost (E\&D\&P) for mobile devices in fog computing environments, using queuing theory. Specifically, three types of queues are applied, namely: mobile devices are considered as a M/M/1 queue, fog node as a M/M/c queue with a defined maximum request rate, and cloud as a M/M/$\infty$ queue. Both wireless transmission and computing capabilities are explicitly and jointly considered when modeling this three-way trade-off. They formulate the optimization problem by finding the optimal offloading probability and transmit power. Using the scalarization method, they were able to transform the multi-objective into a single-objective optimization problem. In order to solve that single-objective problem they proposed an Interior Point Method (IPM)-based algorithm which can reduce the accumulated error and improve the calculation accuracy during the iteration process effectively.\\
%OK
\noindent\tab L. Wang \cite{wang2018moera} et al. address two categories of costs, namely: static, which includes the operation cost and the service quality cost, and dynamic, comprising the reconfiguration cost and the migration cost. While the former is independently incurred inside each time slot, the latter is only charged for decision transitions across consecutive time slots. Operation cost refers to the incurred cost in terms of resources utilization (i.e. Central Processing Unit (CPU) and memory) or energy in each cloudlet. Their approach allows for arbitrary variations on the operation price over time (i.e. can be heterogeneous for different resources). Service quality cost is proportional to the network delay between the user and its workload which may be distributed over several cloudlets. Reconfiguration cost regards to the increase of workload across time slots in each cloudlet. When this happens, infrastructure providers may need to power up other resources, in order to reduce the service quality cost. This incurs new delays inherent to the setup as well as costs of hardware wear-and-tear. This cost is proportional to the increased workload and the reconfiguration price. Finally, the migration cost includes both bandwidth cost on the network and the migration delay (both moving out of and into each cloudlet). Taking into account all these costs for each cloudlet, the problem formulation consists in a weighted sum of these costs. 
%It is observed that, if all inputs were given in advance (operation prices and the user mobility patterns in all time slots), this problem could be solved using a linear program solver. However, this is impossible in the online setting, where the input data are revealed step-by-step over time.
They propose Mobility-agnostic Online Edge Resource Allocation (MOERA) based on the ``regularization'' technique, which decomposes the problem into subproblems and solve them using convex programming. This algorithm receives as input the user‚Äôs workload and location and decides how resources should be allocated, such that the workload demands from every user is fulfilled while the overall cost system is minimized.

\subsection{Concluding Remarks}
The presented literature addresses different objectives regarding optimization of migration in fog environments. For instance in Section \ref{sec:QoS}, the conferred works perform a single objective optimization. The works in Section \ref{sec:bandwidth}, Section \ref{sec:energy} and Section \ref{sec:cost}, besides guarantying QoS to its users, they also aim to minimize bandwidth usage, energy and cost, respectively, presenting a dual objective optimization. In Section \ref{sec:multi} were presented works that combine some of the above mentioned objective.  Although their approaches contribute to the improvement of fog computing, they do not account all the aspects that this work aims to cover. For instance the literature in Section \ref{sec:bandwidth}, intends to reduce the number of migrations by providing long-term QoS, allowing a reduction of downtime service, increasing QoS. For this purpose, some works consider network state and server performance (resulting in workload) in their models. However, they all fail in not considering an energy consumption, a cost model and an environment where fog nodes can be movable. Moreover, in Section \ref{sec:energy} the aim is to minimize the energy consumption of fog infrastructure providers. To this end, they present efficient mechanisms regarding offloading work in an energy-efficient manner while guarantying QoS to its users. Once again, their models do not consider mobile fog nodes nor DDF programming model. Besides, these do not formulate a specific cost model or only consider energy consumption being it's only variable.\\
\noindent\tab Some of these works do not consider mobility, which is an unrealistic assumption. Others, only consider mobility from the IoT devices side or the fog nodes side, disregarding the possibility of having total dynamic fog computing environments. Also, some of them do not consider DDF programming model. As already discussed, it can bring advantages to fog computing. Furthermore, some works penalize migration, and considers that once QoS is being ensured, there is no need to migrate applications/modules. However, as network distance increases, even if time boundaries are met, the bandwidth and resource usage by the intermediate links also increases thus, this trade-off needs to be carefully implemented.