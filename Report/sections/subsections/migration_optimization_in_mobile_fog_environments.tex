%!TEX encoding = UTF-8 Unicode
\subsection{Migration optimization in mobile fog environments}
\label{sec:Migration}
When an IoT device needs to offload some heavy application to a third party, it will be connected to the nearest server, securing an one-hop away fog server to ensure the shortest network delay. However, as their physical distance increases either by device or server movement, their network distance (i.e. the number of hops) will also increase. Hence, both latency and bandwidth usage by the intermediate links will increase, resulting in poor connectivity. This away, in such dynamic environments the decision-making of where to send the VMs, in order to overcome these limitations, is a major concern. Moreover, even if both clients and servers are static, the end-to-end latency may increase due to unexpected crowds of mobile clients seeking to connect or making requests to the same fog server simultaneously.\\
\noindent\tab In Section \ref{sec:Dataplacement} was verified that applications can be offloaded as a whole, or as a set of modules that may have different constraints. Regardless of their type, whenever it is justified the system needs to be readjusted. This is performed through the exchange of VMs (that contain the applications or modules) between fog nodes. For this reason, it is necessary to answer the following two questions: \textit{When is this exchange justified? And what is the best placement for those applications and/or modules?}\\

%%Previous reactive load balancing algorithms migrate VMs upon the occurrence of load imbalance, while previous proactive load balancing algorithms predict PM overload to conduct VM migration
% another works were performd using MDP-based approaches (ex. Distributed Autonomous Virtual Resource Management in Datacenters Using Finite-Markov Decision Process)

\subsubsection{Latency-aware with mobile end-devices}
\noindent\tab In the context of mobile end devices, B Ottenw√§lder et al. \cite{ottenwalder2013migcep} state that as sensors and consumers are mobile, the latency (between the access point of a mobile sensor and the fog node) and bandwidth usage is expected to change over time, so it is necessary to constantly adapt the placement through migrations to new fog nodes. However, each migration comes with a cost; consequence of the local state that also needs to be migrated. Thus, frequent migration would significantly decrease the system performance. To overcome this limitation, they propose a placement and migration method for providers of infrastructures that incorporate cloud and fog resources to support operator migrations in mobile complex event processing (MCEP) systems. Their method plans the migration ahead of time through knowledge of the MCEP system and predicted mobility patterns towards ensuring application-defined end-to-end latency restrictions and reducing the network utilization. These predicted mobility patterns were captured using three different methods: uncertain locations from the \textit{dead reckoning} approach (linear), certain locations that could stem from a \textit{navigation} system (navi), and \textit{learned} transitions between leaf broker (learned). This method, allows a minimization of migration costs by selecting migration targets that ensure a low expected network utilization for a sufficiently long time. Moreover, they present how the application knowledge of the CEP system can be used to improve current live migration techniques for VMs to reduce the required bandwidth during the migration (i.e. unnecessary events are not migrated).\\

\noindent\tab A different approach was adopted in the work of R Urgaonkar et al. \cite{urgaonkar2015dynamic}. Similarly to the previous work, their aim is to provide an optimal decision with regard to: where to migrate a current service as the user location changes. However, they argue that because of the uncertainty in user mobility and request patterns, it is challenging to make the decision in an optimal manner. Also, in this work is argued that methods that depend on mobility patterns have several drawback, namely: (1) it requires extensive knowledge of the statistics of the user mobility and request arrival processes that can be impractical to obtain in a dynamic network, (2) even when this is known, the resulting problem can be computationally challenging to solve, and (3) any change in the statistics would make the previous solution suboptimal and would require recomputing the optimal solution. Thus, they propose a new model, inspired by the technique of Lyapunov optimization, that overcomes these drawbacks (i.e. does not require any knowledge of the transition probabilities). The overall problem of dynamic service migration and workload scheduling to optimize system cost while providing end user performance guarantees is formulated as a sequential decision making problem in the framework of markov decision problems (MDPs). However, they have developed a new approach for solving a class of constrained MDPs that possess a decoupling property. When this property holds, their approach enables the design of simple online control algorithms that do not require any knowledge of the underlying statistics of the MDPs.\\
%This technique was applied to both dynamic service migration and workload scheduling and compared to three other policies: never migrate policy, always migrate policy and myopic policy (recalculate the system parameters in time slots). \\

\noindent\tab W Zhang et al. \cite{zhang2016segue} state that previous studies have proposed a static distance-based MDP for optimizing migration decisions. However, these models fail to consider dynamic network and server states in migration decisions, assuming that all the important variables are known. Moreover, they also point out another unaddressed problem which lies in the recalculation time interval of the method. Since running MPD is a heavy computing task, a short recalculation interval introduces a considerable overhead to the server. On the other hand, a long recalculation interval may translate into lazy migration, meaning that resulting in periods of transgression of QoS guarantees. In order to overcome those issues, the authors propose SEGUE. This model achieves optimal migration decisions by providing a long-term optimal QoS to mobile users in the presence of link quality and server load variation. Additionally, SEGUE adopts a QoS aware scheme to activate the MDP model. In other words, it only activates the MDP model when QoS violation is predicted. Thus, it avoids unnecessary migration costs and bypass any possible QoS violations while keeping a reasonable low overhead in the servers.\\

\noindent\tab The work performed by Wuyang Zhang et al. \cite{Zhang2017} use as case study the Massively Multiplayer Online Gamse (MMOGs) with Virtual Reality (VR) technologies, VR-MMOGs. They present the main challages of VR-MMOGs, namely: stringent latency, high bandwidth, and large scale requirements. This work shows one problem that remains unsolved: how to distribute the work among the user device, the edge clouds, and the center cloud to meet all three requirements especially when users are mobile. Their approach was to place local view change updates on edge clouds for immediate responses, frame rendering on edge clouds for high bandwidth, and global game state updates on the center cloud for user scalability. In this kind of games, the users need to move, so in order to keep a low latency communication, they also ropose an efficient service placement algorithm based on MDP. This method takes into account the presence of dynamic network states and server workload states, and user mobility. To ensure feasibility of this method, they come up with an approach that reduces the algorithm complexity in both storage and execution time. Nonetheless, unlike many of the service migration solutions which assumes an ignorable service transition time, they point out that it is impossible to migrate an edge service from one edge to another instantly given the size of a VR game world. Therefore, they propose a mechanism to ensure a new edge cloud is activated when a player connects to the new one.\\

\noindent\tab S Abdelwahab et al. \cite{abdelwahab2018clones} argue that IoT devices communicate a large number of messages with many devices. Thus, devices with low computing and storage capacities will became another source of latency for large-scale distributed applications. Their experiments show that brokering the messages through a one-hop away broker may reduce significantly the end-to-end latency. Therefore, if devices are cloned in a one-hop away cloudlet, their clones can provide message brokering service, allowing both a communication with minimal latency between devices and to offload intensive computation into rich memory and processing nodes that host the clones. Nonetheless, communicating through a one-hop away clone may still experience long end-to-end latency when the broker service relays messages to distant devices. Hence, they propose FogMQ, a self-deploying brokering clones that discover hosting platforms and autonomously migrate between them according to the measured end-to-end latency. This method does not need a central monitoring and control unit. FogMQ servers expose tomography functionalities that enables clones to take migration decisions without complete knowledge about the hosting platform. It allows to stabilize clones deployment and achieve a near minimum latency given an existing infrastructure limits.\\

\noindent\tab The study performed by X Sun et al. \cite{sun2016primal} presents, similarly to the previous ones, a case scenario where end devices are mobile. To preform this work they use a cloudlet network architecture to bring the computing resources from the centralized cloud to the edge. They present the PRofIt Maximization Avatar pLacement (PRIMAL) strategy. PRIMAL maximizes the trade-off between the migration gain (i.e. the end-to-end delay reduction) and the migration cost (i.e. the migration overheads), selectively migrating the avatars (an application clone located in a cloudlet) to their optimal locations.\\ %Does not address where this strategy is calculated and the time interval (verificar melhor).

\noindent\tab 

\subsubsection{Latency-aware with mobile fog servers}
D Ye et al. \cite{ye2016scalable} leverage the characteristics of buses and propose a scalable fog computing paradigm with servicing offloading in bus networks. Knowing that buses have fixed mobility trajectories and strong periodicity, they consider a fog computing paradigm with service offloading in bus networks which is composed by two parts: roadside cloudlets and bus fog servers. The roadside cloudlet consists of three components: dedicated local servers, location-based service (LBS) providers, access points (APs). The dedicated local servers virtualize physical resource and act as a potential cloud computing site. The LBS providers offer the real time location of each bus in bus networks. The APs act as gateways for mobile users and bus fog servers within the communication coverage to access the roadside cloudlet. When users need to offload some computationally intensive and delay sensitive tasks, they access APs and use the computing service of the roadside cloudlet. However, as cloudlets have limited computational and storage resources, they may became overloaded. The bus fog server is a virtualized computing system on bus, which is similar to a light-weight cloudlet server. Hence, those buses not only provide fog computing services for the mobile users on bus, but also are motivated to accomplish the computation tasks offloaded by roadside cloudlets. This allocation strategy is accomplished using genetic algorithm (GA), where the objective is to minimize the cost that roadside cloudlets spend to offload their computation tasks. Meanwhile, the user experience of mobile users are maintained. Although this work refers to mobile users, its meaning is not literal, being supported only the mobility of fog servers. In their problem formulation there are two types of mobile users. On one hand there are mobile users that already have offloaded their computing tasks to the roadside cloudlets (i.e. representing the workload of the cloudlets). On the other hand there are several mobile users inside the bus that have also offloadded their tasks (i.e. representing the workload of bus fog servers).%foi em que simulador?


%There are two possibilities to answer the question: \textit{when is this exchange justified?}
%In both, it is necessary to monitor the relevant system parameters, however in a different way. The first is to 