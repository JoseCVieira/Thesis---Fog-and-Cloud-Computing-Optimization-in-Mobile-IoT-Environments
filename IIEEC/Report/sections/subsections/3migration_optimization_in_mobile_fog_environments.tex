%!TEX encoding = UTF-8 Unicode
\section{Migration Optimization in Mobile Fog Environments}
\label{sec:Migration}
When an IoT device needs to offload some heavy application to a third party, ideally it will be connected to the nearest server, securing a hop away fog server to ensure the shortest network delay. However, as their physical distance increases either by device or server movement, their network distance (i.e., the number of hops) will also increase. Hence, both latency and bandwidth usage by the intermediate links will increase, resulting in poor connectivity. This away, in such dynamic environments the decision-making of where to offload the work is a major concern. Moreover, even if both clients and servers are static, the end-to-end latency may increase due to unexpected crowds of mobile clients seeking to connect or making requests to the same fog server simultaneously, which may lead to QoS violations.\\
\noindent\tab In Section \ref{sec:fog_architecture} it was discussed that applications can be offloaded as a whole, or as a set of modules which may have different latency constraints. Regardless of their type, whenever it is justified the system needs to be readjusted. This is performed through the exchange of VMs or containers (containing the applications or modules) between fog nodes. For this reason, it is necessary to answer the following questions: \textit{When is this exchange justified? And what is the best placement for those applications and/or modules?} As stated in Section \ref{subsec:Objectives}, this work intends to implement multi-objective management decision-making in a novel architecture. Hence, this state-of-the-art section intends to study some proposed mechanisms in the literature.

\subsection{QoS-Aware}\label{sec:QoS}
The first objective that fog computing has to guarantee is QoS. When users outsource some delay constrained task or application, they expect fog to be adaptive enough so that they can move while their time boundaries are met. Without this objective fog computing is useless once it appears, in part, to help cloud computing to overcome this limitation.\\
%OK
\noindent\tab In this context, the work performed by T. Rodrigues \cite{rodrigues2017pso} et al. is focused on increasing the QoS offered to its users by lowering both transmission and processing delays.
%On the one hand, the transmission delay encompass the time spent to send the data/task to the cloudlet and the time interval to receive the results. On the other hand, processing delay regards to the time that the work spends in the cloudlet's work queue and the respective time to being processed.
Their goal is achieved by finding the best placement of each mobile user's VM. They assume that each user is connected to the cloudlet which offers the best Received Signal Strength (RSS), that, in turn, is also responsible for hosting its VM. Therefore, their goal is to compute the optimal transmitting power for each cloudlet which will control the RSS and, consequently, change user connections. In order to optimize the formulated problem, is applied a Particle Swarm Optimization (PSO) model. Their architecture assumes the presence of a central unit which is responsible for collecting the physical locations of users and cloudlets and then to execute the model. It is worth noting that when any user changes its connection (i.e., connects to another cloudlet), its VM is also migrated, however this delay is not considered. Also, their work considers that each VM task arrival rate follows a Poisson process with the same rate for all users and does not specify what is the algorithm optimal frequency of execution.\\
%OK
\noindent\tab The study performed by X. Sun et al. \cite{sun2016primal} presents, a case scenario where the end devices are mobile. To perform this work they use a cloudlet network architecture to bring the computing resources from the centralized cloud to the edge. They present the PRofIt Maximization Avatar pLacement (PRIMAL) strategy. PRIMAL maximizes the trade-off between the migration gain (i.e., the end-to-end delay reduction) and the migration cost (i.e., the migration overheads incured in the avatar, which compromise its performance), by migrating the avatars (a software clone located in a cloudlet) to their optimal locations, using  pre-copy live migration. To solve the formulated problem, they use the Mixed-Integer Quadratic Programming tool in the CPLEX solver to find the heuristic solution of PRIMAL. It is worth noting that the considered gain only considers the end-to-end delay reduction between the user's base station and user's avatar. Both gain and cost do not consider the servers state nor network state. \\
%R. Urgaonkar et al. \cite{urgaonkar2015dynamic} argue that because of the uncertainty in user mobility and request patterns, it is challenging to make migration decisions in an optimal manner. Also, in this work is argued that methods which depend on mobility patterns have several drawbacks, namely: (1) they require extensive knowledge of the statistics of the user mobility and request arrival processes that can be impractical to obtain in a dynamic network, (2) even when this is known, the resulting problem can be computationally challenging to solve, and (3) any change in the statistics would make the previous solution suboptimal and would require recomputing the optimal solution. Thus, they propose a new model, inspired by the technique of Lyapunov optimization, that overcomes these drawbacks (i.e., does not require any knowledge of the transition probabilities). The overall problem of dynamic service migration and workload scheduling to optimize system cost while providing end user performance guarantees is formulated as a sequential decision-making problem in the framework of Markov Decision Processes (MDPs). The cost depends on reconfiguration cost, inherent to migration services (i.e., moving the application from one cloudlet to another) and on transmission cost (i.e., time-average of user-to-cloudlet request routing) which depends on their distance. Their goal is to design a control algorithm for making request routing decisions so that the time-average overall transmission and reconfiguration costs are minimized while serving all requests with finite delay. They have developed a new approach for solving a class of constrained MDPs that possess a decoupling property. When this property holds, their approach enables the design of simple online control algorithms that do not require any knowledge of the underlying statistics of the MDPs.

\subsection{Bandwidth-Aware}\label{sec:bandwidth}
Minimization of network utilization is one of the main objectives of fog computing. In fact, fog appears to overcome this inherent limitation of cloud computing. Thus, aside from ensuring QoS, it is also important to reduce bandwidth usage.
%Thus, besides guarantee QoS, it is also  important to reduce bandwidth usage.
This utilization of network is essentially due to three factors: the transmission of virtualized resources (VMs or containers) which contain the applications/modules, transmission of data between the end device and the deployed application into the fog nodes, and control messages exchanged between fog nodes. If the applications are deployed using DDF programming model a fourth factor rises, the data transmission between modules. In this section, the reviewed literature propose models to mitigate bandwidth usage providing long-term QoS, reducing the number of migrations.\\
%
\noindent\tab B. Ottenwälder et al. \cite{ottenwalder2013migcep} consider an environment with mobile devices and fixed fog nodes, where users offload real-time applications such as Complex Event Processing (CEP). CEP is a paradigm where changes in sensor measurements are modeled as events, while the application is modeled as set of event-driven operators. They state that each migration comes with a cost, consequence of the local state that also needs to be migrated along with the operators. Thus, frequent migration would significantly decrease the system performance. To overcome this limitation, they propose a placement and migration method for fog providers to support operator migrations in Mobile Complex Event Processing (MCEP) systems. Their method plans the migration ahead of time through knowledge of the MCEP system and predicted mobility patterns towards ensuring application-defined end-to-end latency restrictions and reducing the network utilization. These predicted mobility patterns were captured using three different methods: uncertain locations from the \textit{dead reckoning} approach (linear), certain locations that could stem from a \textit{navigation} system (navi), and \textit{learned} transitions between leaf broker (learned). This method allows a minimization of migration costs by selecting migration targets that ensure a low expected network utilization for a sufficiently long time.\\ %Moreover, they present how the application knowledge of the CEP system can be used to improve current live migration techniques for VMs to reduce the required bandwidth during the migration (i.e., unnecessary events are not migrated).\\
%OK1
\noindent\tab Also in this context, W. Zhang et al. \cite{zhang2016segue} state that previous studies have proposed a static distance-based MDP for optimizing migration decisions. However, these models fail to consider dynamic network and server states in migration decisions, assuming that all the important variables are known. Moreover, they also point out another unaddressed problem which lies in the recalculation time interval of the method. Since running MDP is a heavy computing task, a short recalculation interval introduces a considerable overhead to the server. On the other hand, a long recalculation interval may translate into lazy migration, resulting in periods of transgression of QoS guarantees. In order to overcome these issues, the authors propose SEGUE. This model achieves optimal migration decisions by providing a long-term optimal QoS to mobile users in the presence of link quality and server load variation. Additionally, SEGUE adopts a QoS aware scheme to activate the MDP model. In other words, it only activates the MDP model when QoS violation is predicted. Thus, it avoids unnecessary migration costs and bypasses any possible QoS violations while keeping a reasonable low overhead in the servers.
%The QoS prediction module assumes that mobile location, follows a mobility pattern with only one dimension.
The problem formulation is then formulated as a cost-reward between the predicted long term QoS improvement and the service downtime.\\
%The work performed by Wuyang Zhang et al. \cite{zhang2017towards} use as case study the Massively Multiplayer Online Gamse (MMOGs) with Virtual Reality (VR) technologies, VR-MMOGs. They present the main challenges of VR-MMOGs, namely: stringent latency, high bandwidth, and large scale requirements. This work shows one problem that remains unsolved: how to distribute the work among the user device, the fog nodes, and the center cloud to meet all three requirements especially when users are mobile. Their approach was to place local view change updates on fog nodes for immediate responses, frame rendering on fog nodes for high bandwidth, and global game state updates on the center cloud for user scalability. In this kind of game, users need to move, so in order to keep a low latency communication, they also propose an efficient service placement algorithm based on MDP. This method takes into account the presence of dynamic network states and server workload states, and user mobility providing long-term QoS. To ensure feasibility of this method, they come up with an approach that reduces the algorithm complexity in both storage and execution time. Nonetheless, unlike many of the service migration solutions which assumes an ignorable service transition time, they point out that it is impossible to migrate a fog service from one fog to another instantly given the size of a VR game world. Therefore, they propose a mechanism to ensure a new fog node is activated when a player connects to the new one.
%\\ \textit{Concluding Remarks} - The presented literature intends to reduce the number of migrations by providing long term QoS. This also reduces the downtime service, increasing QoS. While the first work, considers distributed applications, where the set of operators which are deployed among a set of fog nodes need some coordination in migrations, the rest consider applications as a whole. As already discussed, DDF programming model can bring advantages to fog computing. However the two latter works consider network state and server performance (resulting in workload) in their models. They all fail in not consider an energy consumption, a cost model and an environment where fog nodes can be movable.

\subsection{Energy-Aware}\label{sec:energy}
In order to achieve the QoS objective, the placement of applications and their modules has often to be moved between different entities that compose the things-fog-cloud architecture which evolves energetic costs (both in terms of processing and communication). For instance, it is needed to exchange control messages, communicate between modules placed at different nodes, change the module placement, etc. Thus, energy-aware must be an important factor to be taken into account in the decision making algorithm of \textit{when} and \textit{where} to offload work to another entity in order to minimize fog infrastructure providers' cost.\\
%OK1
\noindent\tab In this context, R. Deng et al. \cite{deng2016optimal} focused on investigating system power consumption and network delay trade-off in cloud-fog services. They formulate a workload allocation problem, which suggests the optimal workload allocations between fog and cloud toward the minimal power consumption with the constrained service delay. This was performed through the modeled power consumption and delay functions of each part of the fog-cloud computing system. It is worth noting that power consumption only considers energy consumption of work computation, disregarding communication costs. The problem is then tackled using an approximate approach through decomposition, and formulation of three subproblems, being solved through existing optimization techniques. This work also does not considers dynamic environments. All variables are static including the position of fog nodes and end devices. Also there is no cooperation between fog nodes and the communication delay between a fog node and a cloud server is only characterized by its latency, ignoring the bandwidth. Similarly to the majority of the presented works, the decision-making is performed in a centralized manner.\\
%OK1
\noindent\tab Y. Xiao et al. \cite{xiao2017qoe} investigate two performance metrics for fog computing networks: the QoS of mobile users and the power efficiency of fog nodes. In their scheme, fog nodes can process or offload to other fog nodes part of the workload that was initially sent to the cloud. Fog nodes decide whether to offload the workload to neighbors or locally process it, under a given power constraint. A distributed optimization algorithm based on Alternating Direction Method of Multipliers (ADMM) via variable splitting is proposed. This allows to achieve the optimal workload allocation solution that maximizes QoS of users under the given power efficiency. In this work, power efficiency of each fog node is measured by the amount of consumed energy to offload each unit of workload from the cloud. Note that their work do not use the concept of VMs nor DDF programming model, and the considered environment is static (i.e., nodes and clients are static), avoiding the inherent migration problems.
%\noindent\tab C. Anglano et al. \cite{anglano2018profit} present the Online Profit Maximization (OPM) algorithm. It is an approximation algorithm that aims to increase fog infrastructure providers' profit, by reducing the overall energy consumption of the infrastructure without a priori knowledge, and yet guarantee the QoS to its mobile end users. This cost is the sum of energy costs inherited from the execution of applications, cloning and migrating the VMs, turning on and off the fog nodes, and monetary penalties for QoS violations. To solve the formulated problem, their work applies an online optimization algorithm in each recalculation time interval, achieving near optimal solutions.\\(TEM CLONES E DEVIA ESTAR NO CUSTO)
%\noindent\tab The work performed by A. Kattepur et al. \cite{kattepur2016resource} investigates the problem of computation offloading in fog computing. They present an energy model and communication costs with respect to computational offloading and formulate an optimal deployment strategy when dealing with distributed computation, while keeping energy and latency constraints in mind. The formulations are solved in Scilab using the Karmarkar linear optimization solver. They evaluate their approach in a sense-process-actuate model using a network of mobile robotic sensor-actuators developed in Robot Operating System (ROS)/Gazebo.(PEERS ROBOT/FOG NODE)\\
%OK1
\subsection{Cost-Aware}\label{sec:cost}
As aforementioned, besides guarantying QoS to its users, fog service providers also need to maximize their profit. Hence, it is important to develop an accurate cost model in order to accept and implement fog computing. Besides, similarly to what cloud does, fog has to implement a pay-as-you-go cost model in order to provide services on-demand to its users, without under- or over-provisioning, and charging a fair price. To this end, the cost model needs to apply a communication model, an energy model, and a resource utilization model.\\
%OK1
\noindent\tab In this context, L. Gu et al. \cite{gu2017cost} state the importance of fog computing in medical cyber-physical systems as the number of users grows. They state that different infrastructure service providers may apply different charging policies. Therefore, in this paper, the authors aim to minimize the overall resource management cost while satisfying the QoS requirements. They formulate the cost minimization problem in a form of Mixed-Integer NonLinear Programming (MINLP) with joint consideration of communication BS association, subcarrier allocation, computation BS association, VM deployment and task distribution. To tackle the high computational complexity of solving this problem, they linearize it into a Mixed-Integer Linear Programming (MILP) problem. This way they are able to solve the optimal programming model using solvers such as CPLEX and Gurobi. However, it is still time-consuming due to the existence of many integer variables. To this end, they further propose an LP-based two-phase heuristic algorithm. It is worth noting that this work explores placement of VMs in fog computing, whereas it does not tackle this problem in mobile environments, disregarding both users and servers mobility, consequently not addressing the inherent migration problems. Moreover, the proposed method to verify if the QoS requirements are met do not consider the servers state nor network state.\\
%OK1OK
\noindent\tab O. Skarlat et al. \cite{skarlat2017optimized} start by describing a conceptual framework for resource provisioning and service placement in fog. They consider the concept of fog colonies (refer to Section \ref{sec:fog_arch_orchestration}) using a cooperative execution of IoT applications (DDF programming model). Based on this concept, their work, formalizes an optimization problem that aims to adhere to the deadlines on deployment and execution time of applications and to maximize the utilization of existing resources in fog, rather than in cloud, leading to lower execution cost. To solve this placement problem, they apply different approaches, namely the exact optimization method and its approximation through a greedy first fit heuristic and a Genetic Algorithm (GA). They also compare the results, in the fog simulation toolkit iFogSim, to a classical approach that neglects fog resources and runs all services in a centralized cloud. The goal of the evaluation is to identify the best approach to solve the proposed optimization problem in terms of resulting QoS, QoS violations, and cost. The latter is composed only by the execution costs in cloud infrastructures, neglecting execution costs in fog nodes. Their work does not provide mobility mechanisms, not addressing the inherent migration problems. Moreover, all the communications within each fog colony need to be performed through the respective fog orchestration control, introducing new non-negligible communication latencies. Also, the proposed method to verify if the QoS requirements are met do not consider the servers state nor network state.\\
%OK1
\noindent\tab The work performed by T. Bahreini et al. \cite{bahreini2017efficient} also addresses multi-tier placement (DDF programming model). The authors formulate the Multi-Component Application Placement Problem (MCAPP). Their objective is to find a mapping between components and servers, such that the total placement cost is minimized. This cost is composed of four types of costs at each time slot: (1) the cost of running one component in a specific server, (2) cost of relocating one component from one server to another, (3) communication cost between one component and the user, and (4) communication between components. With the objective to minimize the overall cost incurred when running the application, they formulate the offine version of the problem as a Mixed Integer Linear Program (MILP) and then developed a heuristic algorithm for solving the online version of the problem. The algorithm is based on an iterative matching process followed by a locals search phase in which the solution quality is improved. This way they use simple algorithmic techniques, avoiding complex approaches such as those based on MDPs. They state that the proposed algorithm has low complexity and adds a negligible overhead to the execution of the applications. Although this work considers the location of servers in the estimation of costs (2) through (4), it does not consider an environment with mobile fog nodes. Also, it only considers the presence of only one user with only one application. Moreover, in each time slot, each server is used by at most one component, not properly taking advantage of fog computing.\\
%
\noindent\tab A different approach was taken by D. Ye et al. \cite{ye2016scalable}. They leverage the characteristics of buses and propose a scalable fog computing paradigm with servicing offloading in bus networks. Knowing that buses have fixed mobility trajectories and strong periodicity, they consider a fog computing paradigm with service offloading in bus networks which is composed by roadside cloudlets and bus fog servers. The roadside cloudlet consists of three components: dedicated local servers, location-based service (LBS) providers, access points (APs). The dedicated local servers virtualize physical resources and act as a potential cloud computing site. LBS providers offer the real time location of each bus in bus networks. APs act as gateways for users and bus fog servers within the communication coverage to access the roadside cloudlet. As cloudlets have limited computational and storage resources, they may become overloaded. The bus fog server is a virtualized computing system on bus, which is similar to a light-weight cloudlet server. Hence, those buses not only provide fog computing services for the users on bus, but also are motivated to accomplish the computation tasks offloaded by roadside cloudlets. This allocation strategy is accomplished using GA, where the objective is to minimize the cost that roadside cloudlets spend to offload their computation tasks. Note that there is only considered mobility of fog nodes (i.e., users are static). Also, their problem assumes the applications are deployed as a whole, not addressing the DDF programming model advantages and difficulties in fog computing. Nonetheless, the proposed method to verify if the QoS requirements are met do not consider the servers state nor network state. 
%Although this work refers to mobile users, its meaning is not literal (representing the workload of both buses and cloudlets), being supported only the mobility of fog servers.

\subsection{Multi-Objective}\label{sec:multi}
In some cases rather than only one objective, it might be indispensable to improve the system performance from several perspectives/objectives. However, those can be independent and conflicting objectives. Therefore, unlike the previous sections, the current one aims to present works that were intended to study multi-objective migration optimization algorithms.\\
\noindent\tab Y. Nan et al. \cite{nan2017adaptive} aim to provide an energy-efficient data offloading mechanism to ensure minimization of long-term system cost (measured by the money spending on energy consumption) and yet guarantee that users do not perceive a poor QoS. Their work assumes that fog nodes have two sources of energy. The primary source is the solar or green energy which has no monetary cost, however it is finite (in each time slot, the volume of electricity converted from solar energy is a stochastic value depending on the weather conditions). As a backup energy supply, fog nodes have also access to the non-free grid or brown power supply. In addiction, they also assume the presence of cloud data centers which, in this case, have only access to the grid power supply. Their work describes an online adaptive algorithm, Lyapunov Optimization on Time and Energy Cost (LOTEC). LOTEC is a quantified near optimal solution and is able to make control decision on application offloading by adjusting the two-way trade-off between average response time and average cost. This decision-making distributes the incoming applications to the corresponding tiers without a priori knowledge of users and system status. Note that, in this work, there are no VM support nor DDF programming model. Also, there is no fog cooperation and both users and fog nodes are static, not addressing the inherent problems of migration.\\
%OK1
\noindent\tab The work performed by L. Yang et al. \cite{yang2016cost} aim to minimize both the average latency of all the users’ request loads and the overall costs of service providers. The latter is composed by minimization of both resource usage on cloudlets and service placement transitions. The authors state that this three-way trade-off is a difficult problem. Moreover, the request load could vary significantly and frequently in both spatial and temporal domain due to the mobility of users. Such dynamic request load implies a periodic update of decisions, keeping in mind both the current performance and the expected future workload (using user’s mobility pattern and services access pattern to predict the distribution of user’s future requests). In order to solve this three way trade-off, the authors first formulate the snapshot problem, named Basic Service Placement Problem (BSPP), which aims to optimize the access latency with the capacity constraints of cloudlets. As it is hard to solve, they design a competitive heuristic to BSPP which outperforms a set of benchmark algorithms. Their work further extends BSPP in order to minimize the above three-way trade-off. To do so, they normalize the costs and apply a weighted sum, allowing the formulation of a single objective problem. It is worth noting that this work does not consider DDF programming model, energy and bandwidth models, routing problems nor mobility of fog nodes.\\
%OK1
\noindent\tab L. Wang et al. \cite{wang2018service} address the social VR applications to study the problem of placing VMs deployed in fog environments such that, the total cost in the overall cost in the fog system is minimized. Although motivated by VR applications, the authors state that this problem is fundamental for any applications that require interactions between either mobile user and the respective VM or user and VMs of other users. The placement problem is to decide where to place the service entity of each user among the cloudlets in order to achieve economic operations of cloudlets as well as QoS. This problem is non-trivial due to the following challenges: (1) cloudlets are heterogeneous in terms of activation and running costs, (2) VMs need to exchange metadata frequently with the associated users and other VMs (of other users), and (3) due to the fact that cloudlets are not intentionally designed to simultaneously accommodate many VMs, especially for VR applications where specific hardware such as GPU may be involved, resource contention needs to be controlled. The authors model the aforementioned challenges with four types of cost: activation cost, the placement cost, the proximity cost, and the collocation cost. These costs are then formulated as a single objective problem by using a weighted sum. They formulate the problem as a combinatorial optimization, which is NP-hard. To solve the problem, they propose ITerative Expansion Moves (ITEM) algorithm, a novel algorithm based on iteratively solving a series of minimum graph cuts. The algorithm is flexible and is applicable in both offline/static (i.e., no movement) and online/dynamic (i.e., with users mobility) scenarios. It is worth noting that the concept of DDF is not applied in this work nor considers fog nodes mobility.\\
%OK
\noindent\tab Motivated by the trade-off between local execution power consumption and the offloading delay, the work performed by L. Liu et al. \cite{liu2018multiobjective} has the objective of minimize energy consumption, delay, and payment cost (E\&D\&P) for mobile devices in fog computing environments, using queuing theory. Specifically, three types of queues are applied, namely: mobile devices are considered as a M/M/1 queue, fog node as a M/M/c queue with a defined maximum request rate, and cloud as a M/M/$\infty$ queue. Both wireless transmission and computing capabilities are explicitly and jointly considered when modeling this three-way trade-off. They formulate the optimization problem by finding the optimal offloading probability and transmit power. Using the scalarization method, they were able to transform the multi-objective into a single-objective optimization problem. In order to solve that single-objective problem they proposed an Interior Point Method (IPM)-based algorithm which can reduce the accumulated error and improve the calculation accuracy during the iteration process effectively. Note that, in the considered system, there is no movement and there exists only one fog node, which does not fulfill the ubiquity characteristic of fog computing.\\
%OK
\noindent\tab L. Wang \cite{wang2018moera} et al. address two categories of costs, namely: static, which includes the operation cost and the service quality cost, and dynamic, comprising the reconfiguration cost and the migration cost. While the former is independently incurred inside each time slot, the latter is only charged for decision transitions across consecutive time slots. Operation cost refers to the incurred cost in terms of resources utilization (i.e., Central Processing Unit (CPU) and memory) or energy in each cloudlet. Service quality cost, which aims to capture the user perceived QoS, is proportional to the network delay between the user and its workload which may be distributed over several cloudlets. Reconfiguration cost regards to the increase of workload across time slots in each cloudlet. Finally, the migration cost includes both bandwidth cost on the network and the migration delay (both moving out of and into each cloudlet). The single objective problem formulation takes into account all these costs using a weighted sum.
%It is observed that, if all inputs were given in advance (operation prices and the user mobility patterns in all time slots), this problem could be solved using a linear program solver. However, this is impossible in the online setting, where the input data are revealed step-by-step over time.
They propose Mobility-agnostic Online Edge Resource Allocation (MOERA) based on the ``regularization'' technique, which decomposes the problem into subproblems and solve them using convex programming. This algorithm receives as input the user’s workload and location and decides how resources should be allocated, such that the workload demands from every user is fulfilled while the overall cost system is minimized. Note that their work do not consider the DDF programming model, avoiding its advantages and difficulties in fog computing, and all fog nodes are static.
%Note that although service quality cost intends to capture and minimize user perceived QoS, it only considers the latency between the user and its workload, however QoS should also take into account both network and server state.

\subsection{Concluding Remarks}
The presented literature addresses different objectives regarding optimization in fog environments. For instance in Section \ref{sec:QoS}, the conferred works perform a single objective optimization in order to minimize the QoS offered to the end users. The works in Section \ref{sec:bandwidth}, Section \ref{sec:energy} and Section \ref{sec:cost}, also perform a single objective optimization, however, besides taking into consideration the QoS, they also consider bandwidth usage, energy and cost, respectively. In Section \ref{sec:multi} were presented works that combine, in a multiple objective optimization, some of the above mentioned objectives.\\
\noindent\tab For the sake of analysis between the works described above, Table \ref{tab:literature:features} presents a comparison of the features supported, and Table \ref{tab:literature:problem} compares the problem formulation, from whose perspective the problem is being optmized, as well as the algorithm(s) implemented in order to solve the problem formulation.\\
\noindent\tab Although their approaches contribute to the improvement of fog computing, they do not account all the aspects that this work aims to cover. Regarding Table \ref{tab:literature:features} it is noticeable that there is lack of support for using DDF programming model. As already discussed, in Section \ref{sec:fog_arch_actors}, it can bring advantages to fog computing. Also, some works do not support the use of VM, considering, in this case, only the workload that needs to be processed. However, as previously mentioned, in Section \ref{sec:fog_architecture}, one of the main goals of fog computing is to support running multiple IoT applications at the same time. To do so, it is mandatory to use some kind of virtualization technique as discussed in Section \ref{sec:Introduction}.
%only one application with multiple users performing request to it. As previously mentioned, in Section \ref{sec:fog_architecture}, one of the main goals of fog computing is to support running multiple IoT applications at the same time.
It also is clear that the analyzed works fail to consider a fully dynamic environment. Even though some take into account mobility either from the mobile devices or fog nodes, none of them acknowledges both simultaneously. Migration is also a challenge little explored. However, due to the fact that the environments in which the fog is used are not static, it is crucial in order to rearrange the placement of applications or modules whenever needed. Finally, in order to improve the system flexibility, the presence of multiple fog nodes and the cooperation between them is also essential, however, this is not considered in some cases. \\
\noindent\tab With respect to the optimization problem, Table \ref{tab:literature:problem}, there are several approaches. 
%These works aim to optimize their formulated problem from different perspectives, including: the fog provider which may request resources form a cloud provider, the system provider (i.e., cloud and fog provider), the fixed fog provider which may request resources form a mobile fog provider, the service provider or broker which may request resources from several fog and/or cloud providers in order to allow users to use its service, and finally the mobile devices perspective which may also request resources from several fog and/or cloud providers.
These works aim to optimize their formulated problem from different perspectives. The fog provider perspective owns a fog infrastructure which may request resources form a cloud provider. The system provider assumes the ownership of both fog and cloud infrastructures. The fixed fog provider (special case of fog provider) perspective assumes only the possession of the fixed fog infrastructure. The service provider or broker as the name suggests wants to provide a service to its users, however is owns any physical infrastructure. Finally the mobile devices perspective is similar to the service provider in the sense that needs to request resources from other fog and/or cloud providers, however, in this case, the objectives refer to the mobile devices (e.g., minimize the energy consumption of mobile devices).\\
\noindent\tab Independently from the optimization perspective, we consider that there are some flaws in the reviewed literature. First, in order to support real-time IoT applications, its demands in terms of response deadline should always be a constrain. For instance, if we consider a hard real-time application (e.g., autonomous car controller), in the worst case scenario each deadline have to be guaranteed to be fulfilled. In this regard, it is mandatory to take into account the state of servers and links, however, as aforementioned, most of the works which define QoS constrains do not take these parameters into consideration. Note that the works performed in \cite{deng2016optimal} and \cite{nan2017adaptive} were able to compute the QoS by taking into account these parameters because there work considers no fog cooperation (i.e., the path is always client-fog-cloud). Similarly the work performed in \cite{ottenwalder2013migcep} was also capable to do it, however, as there were fog cooperation, the key element was to know each data and migration routing. Finally, the work \cite{zhang2016segue} also considers these parameters, however, in this case, those were captured with their refined hybrid push/probe technique which introduces some overhead to the system.
From a similar perspective, users may also demand a maximum time to migrate its service due to service degradation during this period. As shown, in Table 2, none of the reviewed works has addressed this issue. Finally, some works do not consider the amount of resources each node can provide (i.e., CPU, memory and storage) and/or do not consider the amount of bandwidth available in the links. As aforementioned, in Section \ref{sec:fog_arch_actors}, nodes can be anything with computational and storage resources and the communications can also be of any type. This way, those constrains should always be accomplished in order to ensure the solution found do no exceed the available resources.\\
\begin{table}
	\caption{Features comparison of the above described works.}
	\scriptsize
	\begin{tabular}{
			>{\arraybackslash}m{0.32in}
			>{\centering\arraybackslash}m{0.41in}
			>{\centering\arraybackslash}m{0.41in} >{\centering\arraybackslash}m{0.41in} >{\centering\arraybackslash}m{0.41in}
			>{\centering\arraybackslash}m{0.41in}
			>{\centering\arraybackslash}m{0.41in}
			>{\centering\arraybackslash}m{0.41in} >{\centering\arraybackslash}m{0.41in}
			>{\centering\arraybackslash}m{0.41in} >{\centering\arraybackslash}m{0.41in}
		}
		\toprule
		Ref. &
		VM support&
		Multiple VM server support&
		DDF&
		Multiple fog nodes&
		Fog cooperation&
		Cloud server&
		Users mobility&
		Fog servers mobility&
		Location aware&
		Migration\\
		\toprule
		\cite{rodrigues2017pso} & \cmark & \cmark & & \cmark & \cmark & & & & \cmark & \cmark \\
		\midrule
		\cite{sun2016primal} & \cmark & \cmark & & \cmark & \cmark & & \cmark & & \cmark & \cmark \\
		\midrule
		\cite{ottenwalder2013migcep} & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & & \cmark & \cmark \\
		\midrule
		\cite{zhang2016segue} & \cmark & \cmark & & \cmark & \cmark & & \cmark & & \cmark & \cmark \\
		\midrule
		\cite{deng2016optimal} & & & & \cmark & & \cmark & & & & \\
		\midrule
		\cite{xiao2017qoe} & & & & \cmark & \cmark & \cmark & & & & \\
		\midrule
		\cite{gu2017cost} & \cmark & \cmark & & \cmark & \cmark & & & & \cmark & \\
		\midrule
		\cite{skarlat2017optimized} & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & & & & \\
		\midrule
		\cite{bahreini2017efficient} & \cmark & & \cmark & \cmark & \cmark & \cmark & \cmark & & \cmark & \cmark \\
		\midrule
		\cite{ye2016scalable} & \cmark & \cmark & & \cmark & \cmark & & & \cmark & \cmark & \\
		\midrule
		\cite{nan2017adaptive} & & & & \cmark & & \cmark & & & & \\
		\midrule
		\cite{yang2016cost} & \cmark & \cmark & & \cmark & \cmark & \cmark & \cmark & & \cmark & \cmark \\
		\midrule
		\cite{wang2018service} & \cmark & \cmark & & \cmark & \cmark & & \cmark & & \cmark & \cmark \\
		\midrule
		\cite{liu2018multiobjective} & & & & & & \cmark & & & & \\
		\midrule
		\cite{wang2018moera} & \cmark & \cmark & & \cmark & \cmark & & \cmark & & \cmark & \cmark \\
		\bottomrule
	\end{tabular}
	\label{tab:literature:features}
\end{table}
\begin{table}
	\caption{Problem comparison of the above described works.}
	\scriptsize
	\begin{tabular}{
			>{\arraybackslash}m{0.15in}
			>{\centering\arraybackslash}m{0.88in} >{\centering\arraybackslash}m{0.08in} >{\centering\arraybackslash}m{0.08in} %>{\centering\arraybackslash}m{0.08in}
			>{\centering\arraybackslash}m{0.08in} >{\centering\arraybackslash}m{0.08in} >{\centering\arraybackslash}m{0.08in} >{\centering\arraybackslash}m{0.08in} >{\centering\arraybackslash}m{0.08in} >{\centering\arraybackslash}m{0.08in} >{\centering\arraybackslash}m{0.08in} >{\centering\arraybackslash}m{0.08in}
			>{\centering\arraybackslash}m{0.08in} >{\centering\arraybackslash}m{0.08in} >{\centering\arraybackslash}m{0.6in}
			>{\centering\arraybackslash}m{1in}
		}
		\toprule
		& & \multicolumn{4}{c}{Objectives} &
		\multicolumn{3}{c}{Variables} &
		\multicolumn{5}{c}{Constrains}\\
		\cmidrule(lr){3-6} \cmidrule(lr){7-9} \cmidrule(lr){10-14}
		Ref. &
		\begin{turn}{0}\shortstack{Optimization\\perspective}\end{turn} &
		\begin{turn}{90}QoS cost\end{turn} &
		\begin{turn}{90}Bandwidth cost\end{turn} &
		%\begin{turn}{90}Processing cost\end{turn} &
		\begin{turn}{90}Power cost\end{turn} &
		\begin{turn}{90}Operational cost\end{turn} &
		\begin{turn}{90}Placement\end{turn} &
		\begin{turn}{90}Data routing\end{turn} &
		\begin{turn}{90}Migration routing\end{turn} &
		\begin{turn}{90}Resources\end{turn} &
		\begin{turn}{90}Bandwidth\end{turn} &
		\begin{turn}{90}Power\end{turn} &
		\begin{turn}{90}QoS deadline\end{turn} &
		\begin{turn}{90}Migration deadline\end{turn} &
		\begin{turn}{0}\shortstack{Optimization\\manner}\end{turn} & \begin{turn}{0}Algorithm\end{turn}\\
		\toprule
		\cite{rodrigues2017pso} & Fog provider & \cmark & & & & \cmark & & & & & & & & Centralized & PSO \\
		\midrule
		\cite{sun2016primal} & Fog provider & \cmark & & & & \cmark & & & \cmark & & & & & Centralized & MIQP \\
		\midrule
		\cite{ottenwalder2013migcep} & System provider & & \cmark & & & \cmark & \cmark & \cmark & \cmark & & & \cmark & & Distributed & Heuristics\\
		\midrule
		\cite{zhang2016segue} & Fog provider & \cmark & & & & \cmark & & & & & & & & Centralized & MDP \\
		\midrule
		\cite{deng2016optimal} & System provider & & & \cmark & & \cmark & & & \cmark & \cmark & & \cmark & & Centralized & GBD, Hungarian, IPM\\
		\midrule
		\cite{xiao2017qoe} & Fog provider & \cmark & & & & \cmark & & & \cmark & & \cmark & & & Distributed & ADMM-based \\
		\midrule
		\cite{gu2017cost} & Service provider & & & & \cmark & \cmark & & & \cmark & & & \cmark & & Centralized & MILP, LP-based \\
		\midrule
		\cite{skarlat2017optimized} & Fog provider & & & & \cmark & \cmark & & & \cmark & & & \cmark & & Distributed & LP, GA \\
		\midrule
		\cite{bahreini2017efficient} & Service provider & & & & \cmark & \cmark & & & & & & & & Centralized & Heuristic, MILP\\
		\midrule
		\cite{ye2016scalable} & Fixed fog provider & & & & \cmark & \cmark & & & \cmark & & & \cmark & & Centralized & GA \\
		\midrule
		\cite{nan2017adaptive} & System provider & \cmark & & & \cmark & \cmark & & & \cmark & \cmark & & \cmark & & Centralized & Lyapunov-based \\
		\midrule
		\cite{yang2016cost} & Service provider & \cmark & & & \cmark & \cmark & & & \cmark & & & & & Centralized & Heuristics \\
		\midrule
		\cite{wang2018service} & Service provider & \cmark & & & \cmark & \cmark & & & & & & & & Centralized & Edmonds–Karp \\
		\midrule
		\cite{liu2018multiobjective} & Mobile devices & \cmark & & \cmark & \cmark & \cmark & & & \cmark & \cmark & & & & Centralized & IPM-based\\
		\midrule
		\cite{wang2018moera} & Service provider & \cmark & & & \cmark & \cmark & & & \cmark & & & & & Centralized & Regularization-based \\
		\bottomrule
	\end{tabular}
	\label{tab:literature:problem}
\end{table}
\noindent\tab As above mentioned, there were identified some flaws in the reviewed literature. Our aim is to propose a novel architecture which allows to overcome them. To do so, this architecture should be flexible enough to allow supporting different applications, each with an arbitrary number of modules with different demands encapsulated in VMs (i.e., allow the use of VMs and DDF programming model). These applications may be deployed by different users located in with arbitrary locations. Servers in our architecture should also be able to support multiple VMs at the same time (if there exists enough available resources), and be able to communicate between them (if there exist some connection), allowing the fog cooperation feature. Moreover, as discussed in Section \ref{subsec:Motivation}, this work aims to implement fog computing in a completely mobile environment, thus it is also objective to support mobility of both users and fog nodes, as well as location awareness. Meanwhile, as there is movement, connections will be changed as time passes by (e.g., handovers may occur and bandwidth of mobile connections may change), therefore some rearrangements in the placement of VMs, through migration, may be necessary in order to ensure all deadlines are met. Nonetheless, as mentioned in Section \ref{sec:Introduction}, the presence of cloud servers are a key element to support fog computing, thus it is also objective to include them. With the above mentioned, this novel architecture covers all the features presented in Table \ref{tab:literature:features}.\\
\noindent\tab Finally, regarding the placement of VMs, our architecture aims to assume the perspective of a system operator (i.e., owns both fog and cloud servers). In this perspective, the main goals are to minimize the energy consumption of the nodes (by considering processing and communication operations) while keeping the percentage of processor and link resources usage as low as possible. This is important because if a new client enters in the system and asks to deploy a new application and in the surrounding nodes there is no available resources, the system either needs to migrate some VMs in order to support the new client or it denies the access to the user. In either case the operator will have negative effects. This is also applied to the case where a deadline from a current running application is no longer ensured. In this case, the operator needs to migrate some VMs, however if the surrounding nodes have no more available resources, migrations might be longer or the number of migrations might be higher. These objectives must be minimized while ensuring the resources of nodes and links are not exceeded and the QoS, both during the application execution and migration, is met. As discussed above, in order to compute the QoS in the worst case scenario, both server and network state should be considered. This way, the problem variables are the placement, data and migration routing.
%For instance the literature in Section \ref{sec:bandwidth}, intends to reduce the number of migrations by providing long-term QoS, allowing a reduction of downtime service, increasing QoS. For this purpose, some works consider network state and server performance (resulting in workload) in their models. However, they all fail in not considering an energy consumption, a cost model and an environment where fog nodes can be movable. Moreover, in Section \ref{sec:energy} the aim is to minimize the energy consumption of fog infrastructure providers. To this end, they present efficient mechanisms regarding offloading work in an energy-efficient manner while guarantying QoS to its users. Once again, their models do not consider mobile fog nodes nor DDF programming model. Besides, these do not formulate a specific cost model or only consider energy consumption being their only variable.\\
%\noindent\tab Some of these works do not consider mobility, which is an unrealistic assumption. Others, only consider mobility from the IoT devices side or the fog nodes side, disregarding the possibility of having total dynamic fog computing environments. Also, some of them do not consider DDF programming model. As already discussed, it can bring advantages to fog computing. Furthermore, some works penalize migration, and considers that once QoS is being ensured, there is no need to migrate applications/modules. However, as network distance increases, even if time boundaries are met, the bandwidth and resource usage by the intermediate links also increases thus, this trade-off needs to be carefully implemented.
